{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GLQLStKwyzgs"
   },
   "source": [
    "# **METAMODELING WITH ARTIFICIAL NEURAL NETWORK**\n",
    "\n",
    "In this notebook, we will use the results of Abaqus analyses in order to build an Artificial Neural Network (ANN) of the Finite Element (FE) analysis solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Orwif6dIvF4t"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Bwj567NSvHv1",
    "outputId": "e91823c3-87c5-47fe-cca9-cd505741e7ff"
   },
   "outputs": [],
   "source": [
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Matplotlib spec\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Palatino']}) # Palatino font\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jqtrSiFqdBTe",
    "outputId": "1cd691d5-fc75-4420-b6e5-d331a6ee9c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMkgB8U2dS1A"
   },
   "source": [
    "When this notebook has been generated the result of the previous line of code is: _'1.5.0'_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZDSnO7jyzg8"
   },
   "source": [
    "We fix the seed in order to obtain reproducible results.\n",
    "\n",
    "__N.B.__ : Reproducible results are obtained every time the runtime is restarded and runned. If you run multiple time the same cell the results will not be reporducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SytMvTAE22lL"
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed=seed)\n",
    "torch.manual_seed(seed=seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Last two lines just when using GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.manual_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bxRgA_ioyzhA"
   },
   "source": [
    "## **Data preprocessing**\n",
    "\n",
    "We start by importing some information about the model used to generate the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "0FZ6R8aeyzhB",
    "outputId": "e6f59f12-68cb-4eb0-dd90-990424b0c8c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Radius</th>\n",
       "      <th>MaxCurvature</th>\n",
       "      <th>MeshSize</th>\n",
       "      <th>Plies</th>\n",
       "      <th>EffectivePlies</th>\n",
       "      <th>Symmetric</th>\n",
       "      <th>Balanced</th>\n",
       "      <th>AnglesFunction</th>\n",
       "      <th>LoadCase</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <td>705</td>\n",
       "      <td>300</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>harmlin</td>\n",
       "      <td>axial</td>\n",
       "      <td>81</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Height  Radius  MaxCurvature  MeshSize  Plies  EffectivePlies  \\\n",
       "Value     705     300      0.001575         5      8               2   \n",
       "\n",
       "       Symmetric  Balanced AnglesFunction LoadCase  Train  Val  Test  \n",
       "Value       True      True        harmlin    axial     81   27    27  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if notebook running in Colab\n",
    "is_colab = 'google.colab' in sys.modules\n",
    "\n",
    "# Model info folder\n",
    "input_folder = './'\n",
    "\n",
    "info = pd.read_csv(input_folder + 'model_info.csv', sep=\";\")\n",
    "info.index = ['Value']\n",
    "eff_plies = int(info['EffectivePlies'].values)\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = ['Train', 'Val', 'Test']\n",
    "for set in sets:\n",
    "    if set not in info.keys():\n",
    "        sets.remove(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIBWzRwLyzhG"
   },
   "source": [
    "At this point we have to import the data set containing the input and output of the FE analysis. The data is stored in a dataframe in which the upper part is associated to the training set and the lower part to the test set. The precise number of upper row belonging to the train set is indicated in the info above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "niD2Q60oyzhG",
    "outputId": "6046f3fb-ed80-4099-aa94-7eb2dd87de49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amplitude1</th>\n",
       "      <th>PhaseShift1</th>\n",
       "      <th>Omega1</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Amplitude2</th>\n",
       "      <th>PhaseShift2</th>\n",
       "      <th>Omega2</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Buckling</th>\n",
       "      <th>Stiffness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.08</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.39</td>\n",
       "      <td>38.52</td>\n",
       "      <td>14.60</td>\n",
       "      <td>76.85</td>\n",
       "      <td>1.27</td>\n",
       "      <td>13.29</td>\n",
       "      <td>235.051</td>\n",
       "      <td>281175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.39</td>\n",
       "      <td>85.65</td>\n",
       "      <td>1.72</td>\n",
       "      <td>7.86</td>\n",
       "      <td>46.78</td>\n",
       "      <td>69.20</td>\n",
       "      <td>0.66</td>\n",
       "      <td>27.25</td>\n",
       "      <td>239.225</td>\n",
       "      <td>388831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.29</td>\n",
       "      <td>45.21</td>\n",
       "      <td>1.29</td>\n",
       "      <td>8.63</td>\n",
       "      <td>87.30</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.56</td>\n",
       "      <td>190.754</td>\n",
       "      <td>465806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.79</td>\n",
       "      <td>62.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.34</td>\n",
       "      <td>16.69</td>\n",
       "      <td>1.16</td>\n",
       "      <td>19.37</td>\n",
       "      <td>182.235</td>\n",
       "      <td>448824.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.92</td>\n",
       "      <td>28.67</td>\n",
       "      <td>0.07</td>\n",
       "      <td>26.28</td>\n",
       "      <td>57.23</td>\n",
       "      <td>84.57</td>\n",
       "      <td>0.48</td>\n",
       "      <td>20.18</td>\n",
       "      <td>248.555</td>\n",
       "      <td>365717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>73.83</td>\n",
       "      <td>10.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>15.26</td>\n",
       "      <td>19.30</td>\n",
       "      <td>48.92</td>\n",
       "      <td>1.81</td>\n",
       "      <td>7.24</td>\n",
       "      <td>225.731</td>\n",
       "      <td>421545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>33.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>36.61</td>\n",
       "      <td>94.59</td>\n",
       "      <td>58.90</td>\n",
       "      <td>0.23</td>\n",
       "      <td>26.93</td>\n",
       "      <td>225.708</td>\n",
       "      <td>194835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>33.40</td>\n",
       "      <td>23.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>7.64</td>\n",
       "      <td>42.03</td>\n",
       "      <td>76.21</td>\n",
       "      <td>0.85</td>\n",
       "      <td>17.11</td>\n",
       "      <td>178.640</td>\n",
       "      <td>452326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>23.20</td>\n",
       "      <td>25.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>32.97</td>\n",
       "      <td>84.96</td>\n",
       "      <td>32.20</td>\n",
       "      <td>0.18</td>\n",
       "      <td>9.29</td>\n",
       "      <td>243.416</td>\n",
       "      <td>322473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>11.04</td>\n",
       "      <td>71.92</td>\n",
       "      <td>0.43</td>\n",
       "      <td>34.01</td>\n",
       "      <td>65.61</td>\n",
       "      <td>71.46</td>\n",
       "      <td>1.15</td>\n",
       "      <td>37.22</td>\n",
       "      <td>242.012</td>\n",
       "      <td>157904.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amplitude1  PhaseShift1  Omega1  Beta1  Amplitude2  PhaseShift2  Omega2  \\\n",
       "0         65.08        20.60    0.39  38.52       14.60        76.85    1.27   \n",
       "1         24.39        85.65    1.72   7.86       46.78        69.20    0.66   \n",
       "2         19.29        45.21    1.29   8.63       87.30        76.00    0.53   \n",
       "3         65.79        62.30    0.25   2.35       20.34        16.69    1.16   \n",
       "4         13.92        28.67    0.07  26.28       57.23        84.57    0.48   \n",
       "..          ...          ...     ...    ...         ...          ...     ...   \n",
       "130       73.83        10.10    0.30  15.26       19.30        48.92    1.81   \n",
       "131       33.20         6.00    1.23  36.61       94.59        58.90    0.23   \n",
       "132       33.40        23.11    0.11   7.64       42.03        76.21    0.85   \n",
       "133       23.20        25.50    0.49  32.97       84.96        32.20    0.18   \n",
       "134       11.04        71.92    0.43  34.01       65.61        71.46    1.15   \n",
       "\n",
       "     Beta2  Buckling  Stiffness  \n",
       "0    13.29   235.051   281175.0  \n",
       "1    27.25   239.225   388831.0  \n",
       "2     2.56   190.754   465806.0  \n",
       "3    19.37   182.235   448824.0  \n",
       "4    20.18   248.555   365717.0  \n",
       "..     ...       ...        ...  \n",
       "130   7.24   225.731   421545.0  \n",
       "131  26.93   225.708   194835.0  \n",
       "132  17.11   178.640   452326.0  \n",
       "133   9.29   243.416   322473.0  \n",
       "134  37.22   242.012   157904.0  \n",
       "\n",
       "[135 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data folder\n",
    "data_folder = './'\n",
    "\n",
    "data_orig = pd.read_csv(data_folder + '/data.csv', sep=';')\n",
    "data = data_orig.drop(columns='Stiffness')\n",
    "data_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9U4RPrnyzhP"
   },
   "source": [
    "The most important step to perform before training our model is the normalization of the variables. Different strategies are possible at this end, among which 2 are the most used:\n",
    "\n",
    "* Range normalization: converts all the values to the range $[0, 1]$\n",
    "\n",
    "* Standard score normalization: forces the variables to have $0$ mean and $1$ standard deviation\n",
    "\n",
    "We will try both to see the effect on the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ZVjkHziyzhQ"
   },
   "outputs": [],
   "source": [
    "def range_norm(x, x_min=None, x_max=None):\n",
    "    \"\"\" Normalization in range [0, 1] \"\"\"\n",
    "    if x_min is None and x_max is None:\n",
    "        x_min = np.min(x, axis=0)\n",
    "        x_max = np.max(x, axis=0)\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "    return x_norm, x_min, x_max\n",
    "\n",
    "def std_norm(x, m=None, s=None):\n",
    "    \"\"\" Normalization with zero mean and unitary standard deviation \"\"\"\n",
    "    if m is None and s is None:\n",
    "        m = np.mean(x, axis=0)\n",
    "        s = np.std(x, axis=0)\n",
    "    x_norm = (x - m) / s\n",
    "    \n",
    "    return x_norm, m, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL3mX63XyzhT"
   },
   "source": [
    "Now we can split the data into training and test set. The two sets have been generate independently during the DOE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "uy149NwNyzhT",
    "outputId": "224f9a13-bed4-4c54-f05e-a4eee762b812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             - - - - - - - \n",
      "            |Problem info:|\n",
      "             - - - - - - -  \n",
      "\n",
      "X_train : (81, 8)  |  Y_train : (81, 2)\n",
      "X_val   : (27, 8)  |  Y_val   : (27, 2)\n",
      "X_test  : (27, 8)  |  Y_test  : (27, 2) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data_orig.drop(['Buckling', 'Stiffness'], axis=1).values\n",
    "Y = data_orig[['Buckling','Stiffness']].values\n",
    "\n",
    "# Train set\n",
    "train_smp = int(info['Train'].values)\n",
    "_X_train = X[:train_smp, :]\n",
    "_Y_train = Y[:train_smp]\n",
    "last = np.copy(train_smp)\n",
    "\n",
    "# Validation set\n",
    "if 'Val' in sets:\n",
    "    val_smp = int(info['Val'].values)\n",
    "    _X_val = X[last:last+val_smp, :]\n",
    "    _Y_val = Y[last:last+val_smp]\n",
    "    last += val_smp\n",
    "\n",
    "# Test set\n",
    "if 'Test' in sets:\n",
    "    test_smp = int(info['Test'].values)\n",
    "    _X_test = X[last:last+test_smp, :]\n",
    "    _Y_test = Y[last:last+test_smp]\n",
    "\n",
    "print('             - - - - - - - ')\n",
    "print('            |Problem info:|')\n",
    "print('             - - - - - - -  \\n')\n",
    "print(\"X_train : {}  |  Y_train : {}\".format(_X_train.shape, _Y_train.shape))\n",
    "print(\"X_val   : {}  |  Y_val   : {}\".format(_X_val.shape, _Y_val.shape))\n",
    "print(\"X_test  : {}  |  Y_test  : {} \\n\".format(_X_test.shape, _Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ngXLJgnf3zs"
   },
   "source": [
    "At this point we can generate the iterable data sets for Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, Y):\n",
    "    \"\"\" Random shuffle of samples in X and y \"\"\"\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    return X[idx], Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "ORbqtnh-yzhR",
    "outputId": "d18315cf-cbc9-40f5-f987-26f6485bba5b"
   },
   "outputs": [],
   "source": [
    "# Normalization training set\n",
    "X_train, x_min, x_max = range_norm(_X_train)\n",
    "Y_train, y_min, y_max = range_norm(_Y_train)\n",
    "\n",
    "# Shuffle training set\n",
    "X_train, Y_train = shuffle_data(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization validation set\n",
    "X_val, _, _ = range_norm(_X_val, x_min=x_min, x_max=x_max)\n",
    "Y_val, _, _ = range_norm(_Y_val, x_min=y_min, x_max=y_max)\n",
    "\n",
    "# Normalization testing set\n",
    "X_test, _, _ = range_norm(_X_test, x_min=x_min, x_max=x_max)\n",
    "Y_test, _, _ = range_norm(_Y_test, x_min=y_min, x_max=y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(_X, _Y, batch_size):\n",
    "    \"\"\" Split the data into k batches \"\"\"\n",
    "\n",
    "    n_samples = _X.shape[0]\n",
    "    leftovers = {}\n",
    "    n_leftovers = n_samples % batch_size\n",
    "    \n",
    "    # Case with all batches of equal size\n",
    "    if n_leftovers != 0:\n",
    "        leftovers[\"X\"] = _X[-n_leftovers:]\n",
    "        leftovers[\"Y\"] = _Y[-n_leftovers:]\n",
    "        _X = _X[:-n_leftovers]\n",
    "        _Y = _Y[:-n_leftovers]\n",
    "\n",
    "    k = np.int(_X.shape[0] / batch_size)\n",
    "        \n",
    "    X_split = np.split(_X, k)\n",
    "    Y_split = np.split(_Y, k)\n",
    "    \n",
    "    # Add leftover samples as last batch\n",
    "    if n_leftovers != 0:\n",
    "        X_split.append(leftovers[\"X\"])\n",
    "        Y_split.append(leftovers[\"Y\"])\n",
    "\n",
    "    return X_split, Y_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "X_train_b, Y_train_b = create_batches(X_train, Y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches dimensions: \n",
      "\n",
      "Batch 0 : input (16, 8)  ,  output : (16, 2)\n",
      "Batch 1 : input (16, 8)  ,  output : (16, 2)\n",
      "Batch 2 : input (16, 8)  ,  output : (16, 2)\n",
      "Batch 3 : input (16, 8)  ,  output : (16, 2)\n",
      "Batch 4 : input (16, 8)  ,  output : (16, 2)\n",
      "Batch 5 : input (1, 8)  ,  output : (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Batches dimensions: \\n\")\n",
    "for i in range(len(X_train_b)):\n",
    "    print(\"Batch {} : input {}  ,  output : {}\".format(i, X_train_b[i].shape, Y_train_b[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7O7AIIoyzhU"
   },
   "source": [
    "## **Neural network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vyx3cytYfs7E"
   },
   "source": [
    "First define network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aMiO2DUfrIK"
   },
   "outputs": [],
   "source": [
    "class FFNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(FFNN, self).__init__()\n",
    "        # First hidden layer\n",
    "        self.W_1 = Parameter(init.xavier_normal_(torch.Tensor(H, D_in)))\n",
    "        self.b_1 = Parameter(init.constant_(torch.Tensor(H), 0))\n",
    "        # Second hidden layer\n",
    "        self.W_2 = Parameter(init.xavier_normal_(torch.Tensor(H, H)))\n",
    "        self.b_2 = Parameter(init.constant_(torch.Tensor(H), 0))\n",
    "        # Third hidden layer\n",
    "        self.W_3 = Parameter(init.xavier_normal_(torch.Tensor(H, H)))\n",
    "        self.b_3 = Parameter(init.constant_(torch.Tensor(H), 0))\n",
    "        # Output layer\n",
    "        self.W_4 = Parameter(init.xavier_normal_(torch.Tensor(D_out, H)))\n",
    "        self.b_4 = Parameter(init.constant_(torch.Tensor(D_out), 0))\n",
    "        \n",
    "        # define activation function in constructor\n",
    "        self.activation_1 = torch.nn.ReLU()\n",
    "        self.activation_2 = torch.nn.ReLU()\n",
    "        self.activation_3 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.linear(x, self.W_1, self.b_1)\n",
    "        x = self.activation_1(x)\n",
    "        x = F.linear(x, self.W_2, self.b_2)\n",
    "        x = self.activation_2(x)\n",
    "        x = F.linear(x, self.W_3, self.b_3)\n",
    "        x = self.activation_3(x)\n",
    "        pred = F.linear(x, self.W_4, self.b_4)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "ibkHXkYKmXs6",
    "outputId": "3a2927df-9996-474a-eee5-3ec0d6f12263",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_x = X_train.shape[1]\n",
    "n_y = Y_train.shape[1]\n",
    "D_in, H, D_out = n_x, 8, n_y\n",
    "\n",
    "model = FFNN(D_in, H, D_out)\n",
    "\n",
    "epochs = 50000\n",
    "lr = 1e-3\n",
    "weight_decay = 5e-3\n",
    "\n",
    "# Flag True if you are in the network optimization process.\n",
    "is_optimizing = True\n",
    "\n",
    "# If weight_NN exists and we are not in optimization mode just load\n",
    "# network weights and evaluate the model.\n",
    "if(os.path.isfile('net_weights/weights_NN') and is_optimizing==False):\n",
    "    model.load_state_dict(torch.load('net_weights/weights_NN'))\n",
    "    print(model.eval())\n",
    "else:\n",
    "    criterion = nn.MSELoss(reduction='mean') \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # Initialize losses lists.\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    losses = []\n",
    "    \n",
    "    idx = np.arange(len(X_train_b))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        curr_loss = 0\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "        model.train()\n",
    "        for batch_num in idx:\n",
    "            \n",
    "            # Create torch variables, required dtype 'float32' no 'float64'\n",
    "            batch_x = Variable(torch.from_numpy(X_train_b[batch_num].astype('float32')))\n",
    "            batch_y = Variable(torch.from_numpy(Y_train_b[batch_num].astype('float32')))\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(batch_x)\n",
    "            \n",
    "            batch_loss = criterion(y_pred, batch_y)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            curr_loss += batch_loss\n",
    "            \n",
    "        train_loss.append(curr_loss.item() / len(idx))\n",
    "        \n",
    "        model.eval()\n",
    "        val_x = Variable(torch.from_numpy(X_val.astype('float32')))\n",
    "        val_y = Variable(torch.from_numpy(Y_val.astype('float32')))\n",
    "        val_pred = model(val_x)\n",
    "        loss_val = criterion(val_pred, val_y)\n",
    "            \n",
    "        val_loss.append(loss_val.item())\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Iteration : {} | Train loss : {:.5f} | Val loss : {:.5f}\".format(epoch, train_loss[epoch], val_loss[epoch]))\n",
    "\n",
    "    torch.save(model.state_dict(), 'weights_NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : 0.3638, 0.8316  |  Prediction : 0.4681, 0.7057  |  Error : 0028.68%, 0015.14%\n",
      "True : 0.3959, 0.5257  |  Prediction : 0.5849, 0.5232  |  Error : 0047.76%, 0000.46%\n",
      "True : 0.7227, 0.6914  |  Prediction : 0.4974, 0.7035  |  Error : 0031.18%, 0001.74%\n",
      "True : 0.8112, 0.5329  |  Prediction : 0.6547, 0.6297  |  Error : 0019.29%, 0018.16%\n",
      "True : 0.5953, 0.5242  |  Prediction : 0.5351, 0.5657  |  Error : 0010.11%, 0007.92%\n",
      "True : 0.7859, 0.2206  |  Prediction : 0.5705, 0.2897  |  Error : 0027.40%, 0031.31%\n",
      "True : 0.0819, 0.9479  |  Prediction : 0.1012, 0.8987  |  Error : 0023.57%, 0005.19%\n",
      "True : 0.4528, 0.2445  |  Prediction : 0.6051, 0.3657  |  Error : 0033.63%, 0049.58%\n",
      "True : 0.1739, 0.4272  |  Prediction : 0.4725, 0.4238  |  Error : 0171.66%, 0000.79%\n",
      "True : 0.6732, 0.5245  |  Prediction : 0.5500, 0.5843  |  Error : 0018.31%, 0011.40%\n",
      "True : 0.9800, 0.4190  |  Prediction : 0.8272, 0.4387  |  Error : 0015.59%, 0004.69%\n",
      "True : 0.5051, 0.1334  |  Prediction : 0.5625, 0.1115  |  Error : 0011.37%, 0016.47%\n",
      "True : 0.5098, 0.6726  |  Prediction : 0.4784, 0.6185  |  Error : 0006.16%, 0008.05%\n",
      "True : 0.4639, 0.5078  |  Prediction : 0.5645, 0.6202  |  Error : 0021.70%, 0022.14%\n",
      "True : 0.2317, 0.5020  |  Prediction : 0.2902, 0.4049  |  Error : 0025.25%, 0019.34%\n",
      "True : 0.7682, 0.4772  |  Prediction : 0.7062, 0.4683  |  Error : 0008.07%, 0001.86%\n",
      "True : 0.7371, 0.3232  |  Prediction : 0.5550, 0.1854  |  Error : 0024.70%, 0042.64%\n",
      "True : 0.7057, 0.4324  |  Prediction : 0.5734, 0.3751  |  Error : 0018.74%, 0013.26%\n",
      "True : 0.3458, 0.8470  |  Prediction : 0.1319, 0.9408  |  Error : 0061.85%, 0011.07%\n",
      "True : 0.8485, 0.4688  |  Prediction : 0.6563, 0.3411  |  Error : 0022.66%, 0027.24%\n",
      "True : 0.5830, 0.3740  |  Prediction : 0.5365, 0.3204  |  Error : 0007.98%, 0014.32%\n",
      "True : 0.5010, 0.7880  |  Prediction : 0.3310, 0.8094  |  Error : 0033.93%, 0002.72%\n",
      "True : 0.3598, 0.0468  |  Prediction : 0.4901, 0.1223  |  Error : 0036.21%, 0160.98%\n",
      "True : 0.2785, 0.9412  |  Prediction : 0.1664, 0.8920  |  Error : 0040.25%, 0005.22%\n",
      "True : 0.5094, 0.8499  |  Prediction : 0.1949, 0.8329  |  Error : 0061.74%, 0002.00%\n",
      "True : 0.3974, 0.0223  |  Prediction : 0.5598, 0.1496  |  Error : 0040.86%, 0571.25%\n",
      "True : 0.6676, 0.2393  |  Prediction : 0.4966, 0.2049  |  Error : 0025.61%, 0014.36%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_x = Variable(torch.from_numpy(X_val.astype('float32')))\n",
    "val_y = Variable(torch.from_numpy(Y_val.astype('float32')))\n",
    "\n",
    "val_pred = model(val_x)\n",
    "for i in range(val_y.shape[0]):\n",
    "    err_perc = abs(val_y.numpy() - val_pred.detach().numpy()) / val_y.numpy() * 100\n",
    "    print(\"True : {:.4f}, {:.4f}  |  Prediction : {:.4f}, {:.4f}  |  Error : {:07.2f}%, {:07.2f}%\".\n",
    "          format(*val_y[i, :].numpy(), *val_pred[i, :].detach().numpy(), *err_perc[i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0, 0.05)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(np.arange(epochs), train_loss, 'r', np.arange(epochs), val_loss, 'b')\n",
    "plt.legend(['Train Loss','Validation Loss'])\n",
    "plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "plt.ylim(-.0, .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : 0.0000, 1.0000  |  Prediction : 0.1421, 0.9492  |  Error : -000inf%, 0005.08%\n",
      "True : 0.3511, 0.9285  |  Prediction : 0.2318, 0.8341  |  Error : 0033.98%, 0010.17%\n",
      "True : 1.0000, 0.2829  |  Prediction : 0.6488, 0.3021  |  Error : 0035.12%, -006.78%\n",
      "True : 0.7298, 0.7303  |  Prediction : 0.5278, 0.7440  |  Error : 0027.68%, -001.87%\n",
      "True : 0.4944, 0.0000  |  Prediction : 0.3526, 0.0986  |  Error : 0028.68%, -000inf%\n",
      "True : 0.7922, 0.3160  |  Prediction : 0.6637, 0.4046  |  Error : 0016.22%, -028.04%\n",
      "True : 0.5921, 0.1089  |  Prediction : 0.6719, 0.1797  |  Error : -013.47%, -065.05%\n",
      "True : 0.4387, 0.7176  |  Prediction : 0.3152, 0.8021  |  Error : 0028.14%, -011.77%\n",
      "True : 0.8501, 0.2274  |  Prediction : 0.6345, 0.1888  |  Error : 0025.36%, 0016.97%\n",
      "True : 0.7577, 0.1817  |  Prediction : 0.5090, 0.2294  |  Error : 0032.83%, -026.25%\n",
      "True : 0.1602, 0.8757  |  Prediction : 0.6438, 0.6759  |  Error : -301.91%, 0022.82%\n",
      "True : 0.5556, 0.1890  |  Prediction : 0.4549, 0.3026  |  Error : 0018.14%, -060.10%\n",
      "True : 0.8395, 0.5803  |  Prediction : 0.4845, 0.5147  |  Error : 0042.28%, 0011.30%\n",
      "True : 0.5030, 0.6939  |  Prediction : 0.5236, 0.6096  |  Error : -004.08%, 0012.15%\n",
      "True : 0.7295, 0.6282  |  Prediction : 0.5103, 0.5720  |  Error : 0030.06%, 0008.94%\n",
      "True : 0.2637, 0.6561  |  Prediction : 0.2137, 0.7793  |  Error : 0018.94%, -018.78%\n",
      "True : 0.8220, 0.6024  |  Prediction : 0.5192, 0.6428  |  Error : 0036.84%, -006.72%\n",
      "True : 0.6939, 0.1422  |  Prediction : 0.7839, 0.2093  |  Error : -012.97%, -047.18%\n",
      "True : 0.0386, 0.8774  |  Prediction : 0.1578, 0.8740  |  Error : -308.73%, 0000.38%\n",
      "True : 0.8463, 0.6650  |  Prediction : 0.3751, 0.6278  |  Error : 0055.68%, 0005.59%\n",
      "True : 0.7770, 0.3717  |  Prediction : 0.6352, 0.2959  |  Error : 0018.25%, 0020.41%\n",
      "True : 0.7607, 0.3899  |  Prediction : 0.4891, 0.4949  |  Error : 0035.70%, -026.91%\n",
      "True : 0.5800, 0.7764  |  Prediction : 0.2687, 0.6622  |  Error : 0053.68%, 0014.71%\n",
      "True : 0.5798, 0.1618  |  Prediction : 0.4936, 0.2605  |  Error : 0014.87%, -060.96%\n",
      "True : 0.1370, 0.8598  |  Prediction : 0.3720, 0.7789  |  Error : -171.48%, 0009.42%\n",
      "True : 0.7464, 0.5078  |  Prediction : 0.6845, 0.4695  |  Error : 0008.29%, 0007.54%\n",
      "True : 0.7332, 0.0617  |  Prediction : 0.4279, 0.2178  |  Error : 0041.64%, -252.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_x = Variable(torch.from_numpy(X_test.astype('float32')))\n",
    "test_y = Variable(torch.from_numpy(Y_test.astype('float32')))\n",
    "\n",
    "test_pred = model(test_x)\n",
    "for i in range(test_y.shape[0]):\n",
    "    err_perc = (test_y.numpy() - test_pred.detach().numpy()) / test_y.numpy() * 100\n",
    "    print(\"True : {:.4f}, {:.4f}  |  Prediction : {:.4f}, {:.4f}  |  Error : {:07.2f}%, {:07.2f}%\".\n",
    "          format(*test_y[i, :].numpy(), *test_pred[i, :].detach().numpy(), *err_perc[i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Cyx2vNti_z4"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=30, delta=1e-3, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        if self.val_loss_min > val_loss:\n",
    "            self.val_loss_min = val_loss\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
