{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stepyt/vs_cylinder_ann_pso/blob/master/MLP_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLQLStKwyzgs",
        "colab_type": "text"
      },
      "source": [
        "# **METAMODELING WITH ARTIFICIAL NEURAL NETWORK**\n",
        "\n",
        "In this notebook, we will use the results of Abaqus analyses in order to build an Artificial Neural Network (ANN) of the Finite Element (FE) analysis solver."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Orwif6dIvF4t",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bwj567NSvHv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "72c2868f-170f-4da7-fa39-8104e3da9596"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "\n",
        "! pip install pyrenn\n",
        "import pyrenn as prn\n",
        "\n",
        "from matplotlib import rc\n",
        "rc('font',**{'family':'serif','serif':['Palatino']}) # Palatino font\n",
        "plt.rcParams['pdf.fonttype'] = 42"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyrenn in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyrenn) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZDSnO7jyzg8",
        "colab_type": "text"
      },
      "source": [
        "We fix the seed in order to obtain reproducible results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SytMvTAE22lL",
        "colab": {}
      },
      "source": [
        "seed = 0\n",
        "np.random.seed(seed=seed)\n",
        "torch.manual_seed(seed=seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.cuda.manual_seed(seed=seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxRgA_ioyzhA",
        "colab_type": "text"
      },
      "source": [
        "## **Data preprocessing**\n",
        "\n",
        "We start by importing some information about the model used to generate the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FZ6R8aeyzhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "71fc622d-44e3-4270-f422-f285ca07f015"
      },
      "source": [
        "# Modify parameter to choose the output folder to consider\n",
        "stacking_sequence = 'symmetric'\n",
        "data_set = 'large1.65'\n",
        "load_case = 'torsion'\n",
        "fiber_path = 'harmlin'\n",
        "\n",
        "# Check if notebook running in Colab\n",
        "is_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# Model info folder\n",
        "if is_colab:\n",
        "    input_folder = './'\n",
        "else:\n",
        "    input_folder = '../dataset/' + load_case + '/' + stacking_sequence + '/'\\\n",
        "                    + data_set + '/' + fiber_path + '/'\n",
        "\n",
        "info = pd.read_csv(input_folder + 'model_info.csv', sep=\",\")\n",
        "info.index = ['Value']\n",
        "eff_plies = int(info['EffectivePlies'].values)\n",
        "train_smp = int(info['Train'].values)\n",
        "info.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height</th>\n",
              "      <th>Radius</th>\n",
              "      <th>MaxCurvature</th>\n",
              "      <th>MeshSize</th>\n",
              "      <th>Plies</th>\n",
              "      <th>EffectivePlies</th>\n",
              "      <th>Symmetric</th>\n",
              "      <th>Balanced</th>\n",
              "      <th>AnglesFunction</th>\n",
              "      <th>Train</th>\n",
              "      <th>Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Value</th>\n",
              "      <td>700</td>\n",
              "      <td>300</td>\n",
              "      <td>0.001575</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>harmlin</td>\n",
              "      <td>560</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Height  Radius  MaxCurvature  ...  AnglesFunction  Train  Test\n",
              "Value     700     300      0.001575  ...         harmlin    560   140\n",
              "\n",
              "[1 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIBWzRwLyzhG",
        "colab_type": "text"
      },
      "source": [
        "At this point we have to import the data set containing the input and output of the FE analysis. The data is stored in a dataframe in which the upper part is associated to the training set and the lower part to the test set. The precise number of upper row belonging to the train set is indicated in the info above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niD2Q60oyzhG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "6baf3299-d6d5-4984-cdfe-6852c997325b"
      },
      "source": [
        "# Model info folder\n",
        "if is_colab:\n",
        "    data_folder = './'\n",
        "else:\n",
        "    data_folder = '../dataset/' + load_case + '/' + stacking_sequence + '/'\\\n",
        "                    + data_set + '/' + fiber_path + '/'\n",
        "\n",
        "data_orig = pd.read_csv(data_folder + '/data.csv', sep=',')\n",
        "data = data_orig.drop(columns='Stiffness')\n",
        "data_orig"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Amplitude1</th>\n",
              "      <th>PhaseShift1</th>\n",
              "      <th>Omega1</th>\n",
              "      <th>Beta1</th>\n",
              "      <th>Amplitude2</th>\n",
              "      <th>PhaseShift2</th>\n",
              "      <th>Omega2</th>\n",
              "      <th>Beta2</th>\n",
              "      <th>Amplitude3</th>\n",
              "      <th>PhaseShift3</th>\n",
              "      <th>Omega3</th>\n",
              "      <th>Beta3</th>\n",
              "      <th>Amplitude4</th>\n",
              "      <th>PhaseShift4</th>\n",
              "      <th>Omega4</th>\n",
              "      <th>Beta4</th>\n",
              "      <th>Buckling</th>\n",
              "      <th>Stiffness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23.669</td>\n",
              "      <td>35.674</td>\n",
              "      <td>1.409</td>\n",
              "      <td>43.196</td>\n",
              "      <td>14.879</td>\n",
              "      <td>-37.111</td>\n",
              "      <td>1.147</td>\n",
              "      <td>1.143</td>\n",
              "      <td>-43.219</td>\n",
              "      <td>88.109</td>\n",
              "      <td>1.061</td>\n",
              "      <td>-45.257</td>\n",
              "      <td>136.391</td>\n",
              "      <td>-7.020</td>\n",
              "      <td>0.587</td>\n",
              "      <td>89.224</td>\n",
              "      <td>18065.4</td>\n",
              "      <td>6807812.096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-10.608</td>\n",
              "      <td>-47.271</td>\n",
              "      <td>1.311</td>\n",
              "      <td>-62.455</td>\n",
              "      <td>-49.425</td>\n",
              "      <td>-48.961</td>\n",
              "      <td>1.355</td>\n",
              "      <td>-56.506</td>\n",
              "      <td>154.620</td>\n",
              "      <td>3.480</td>\n",
              "      <td>0.695</td>\n",
              "      <td>-66.452</td>\n",
              "      <td>-2.876</td>\n",
              "      <td>9.663</td>\n",
              "      <td>1.668</td>\n",
              "      <td>-10.296</td>\n",
              "      <td>-22731.8</td>\n",
              "      <td>2609794.560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46.250</td>\n",
              "      <td>-2.260</td>\n",
              "      <td>0.923</td>\n",
              "      <td>-40.437</td>\n",
              "      <td>20.162</td>\n",
              "      <td>-83.127</td>\n",
              "      <td>1.961</td>\n",
              "      <td>-52.351</td>\n",
              "      <td>18.899</td>\n",
              "      <td>-58.558</td>\n",
              "      <td>1.067</td>\n",
              "      <td>-14.622</td>\n",
              "      <td>-6.272</td>\n",
              "      <td>65.728</td>\n",
              "      <td>1.788</td>\n",
              "      <td>7.627</td>\n",
              "      <td>-18647.4</td>\n",
              "      <td>4156273.152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-19.562</td>\n",
              "      <td>-70.532</td>\n",
              "      <td>1.076</td>\n",
              "      <td>18.431</td>\n",
              "      <td>-83.234</td>\n",
              "      <td>-65.242</td>\n",
              "      <td>1.509</td>\n",
              "      <td>-69.464</td>\n",
              "      <td>-17.323</td>\n",
              "      <td>20.625</td>\n",
              "      <td>1.570</td>\n",
              "      <td>57.143</td>\n",
              "      <td>87.210</td>\n",
              "      <td>28.914</td>\n",
              "      <td>1.926</td>\n",
              "      <td>79.595</td>\n",
              "      <td>-20191.1</td>\n",
              "      <td>5115148.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.180</td>\n",
              "      <td>84.170</td>\n",
              "      <td>0.851</td>\n",
              "      <td>-43.533</td>\n",
              "      <td>62.261</td>\n",
              "      <td>-13.888</td>\n",
              "      <td>0.575</td>\n",
              "      <td>-12.020</td>\n",
              "      <td>6.920</td>\n",
              "      <td>-26.763</td>\n",
              "      <td>1.920</td>\n",
              "      <td>23.756</td>\n",
              "      <td>-7.832</td>\n",
              "      <td>-16.484</td>\n",
              "      <td>1.595</td>\n",
              "      <td>-6.548</td>\n",
              "      <td>-16820.4</td>\n",
              "      <td>5806592.512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>20.341</td>\n",
              "      <td>89.555</td>\n",
              "      <td>0.277</td>\n",
              "      <td>-88.706</td>\n",
              "      <td>-5.957</td>\n",
              "      <td>54.018</td>\n",
              "      <td>1.971</td>\n",
              "      <td>19.139</td>\n",
              "      <td>8.400</td>\n",
              "      <td>-47.485</td>\n",
              "      <td>1.804</td>\n",
              "      <td>25.982</td>\n",
              "      <td>-43.375</td>\n",
              "      <td>54.831</td>\n",
              "      <td>0.215</td>\n",
              "      <td>10.073</td>\n",
              "      <td>-21732.0</td>\n",
              "      <td>2313146.880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>-24.083</td>\n",
              "      <td>4.468</td>\n",
              "      <td>1.232</td>\n",
              "      <td>36.891</td>\n",
              "      <td>-125.757</td>\n",
              "      <td>20.249</td>\n",
              "      <td>1.122</td>\n",
              "      <td>-71.272</td>\n",
              "      <td>-101.682</td>\n",
              "      <td>80.466</td>\n",
              "      <td>1.319</td>\n",
              "      <td>67.270</td>\n",
              "      <td>-94.104</td>\n",
              "      <td>-10.741</td>\n",
              "      <td>0.431</td>\n",
              "      <td>1.959</td>\n",
              "      <td>-28516.8</td>\n",
              "      <td>5713931.264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>-18.345</td>\n",
              "      <td>-19.800</td>\n",
              "      <td>1.038</td>\n",
              "      <td>5.217</td>\n",
              "      <td>7.609</td>\n",
              "      <td>-78.712</td>\n",
              "      <td>1.874</td>\n",
              "      <td>-25.637</td>\n",
              "      <td>-14.798</td>\n",
              "      <td>-49.755</td>\n",
              "      <td>0.374</td>\n",
              "      <td>10.105</td>\n",
              "      <td>9.312</td>\n",
              "      <td>-26.508</td>\n",
              "      <td>1.515</td>\n",
              "      <td>13.854</td>\n",
              "      <td>-12756.4</td>\n",
              "      <td>4143940.864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>-64.509</td>\n",
              "      <td>57.324</td>\n",
              "      <td>0.632</td>\n",
              "      <td>-27.338</td>\n",
              "      <td>-7.414</td>\n",
              "      <td>-59.336</td>\n",
              "      <td>1.625</td>\n",
              "      <td>1.859</td>\n",
              "      <td>61.666</td>\n",
              "      <td>-19.991</td>\n",
              "      <td>0.585</td>\n",
              "      <td>81.997</td>\n",
              "      <td>-20.811</td>\n",
              "      <td>8.215</td>\n",
              "      <td>1.548</td>\n",
              "      <td>43.853</td>\n",
              "      <td>-17352.6</td>\n",
              "      <td>4617006.080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>4.302</td>\n",
              "      <td>-37.491</td>\n",
              "      <td>1.428</td>\n",
              "      <td>59.696</td>\n",
              "      <td>-199.366</td>\n",
              "      <td>26.338</td>\n",
              "      <td>0.234</td>\n",
              "      <td>-48.279</td>\n",
              "      <td>-117.021</td>\n",
              "      <td>-8.386</td>\n",
              "      <td>0.190</td>\n",
              "      <td>-54.427</td>\n",
              "      <td>22.352</td>\n",
              "      <td>17.734</td>\n",
              "      <td>1.136</td>\n",
              "      <td>79.289</td>\n",
              "      <td>21439.5</td>\n",
              "      <td>8151009.792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>700 rows Ã— 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Amplitude1  PhaseShift1  Omega1  ...   Beta4  Buckling    Stiffness\n",
              "0        23.669       35.674   1.409  ...  89.224   18065.4  6807812.096\n",
              "1       -10.608      -47.271   1.311  ... -10.296  -22731.8  2609794.560\n",
              "2        46.250       -2.260   0.923  ...   7.627  -18647.4  4156273.152\n",
              "3       -19.562      -70.532   1.076  ...  79.595  -20191.1  5115148.288\n",
              "4        -4.180       84.170   0.851  ...  -6.548  -16820.4  5806592.512\n",
              "..          ...          ...     ...  ...     ...       ...          ...\n",
              "695      20.341       89.555   0.277  ...  10.073  -21732.0  2313146.880\n",
              "696     -24.083        4.468   1.232  ...   1.959  -28516.8  5713931.264\n",
              "697     -18.345      -19.800   1.038  ...  13.854  -12756.4  4143940.864\n",
              "698     -64.509       57.324   0.632  ...  43.853  -17352.6  4617006.080\n",
              "699       4.302      -37.491   1.428  ...  79.289   21439.5  8151009.792\n",
              "\n",
              "[700 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqfVPfr1yzhL",
        "colab_type": "text"
      },
      "source": [
        "After importing the data we change the sign of the features associated to negeative values of the buckling load, and the sign of the buckling loads. In this way all the critical values have the same sign."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzaIvVw7yzhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# indexes = data['Buckling'].values < 0\n",
        "# data[indexes] = -data[indexes]\n",
        "# data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9U4RPrnyzhP",
        "colab_type": "text"
      },
      "source": [
        "The most important step to perform before training our model is the normalization of the variables. Different strategies are possible at this end, among which 2 are the most used:\n",
        "\n",
        "* Range normalization: converts all the values to the range $[0, 1]$\n",
        "\n",
        "* Standard score normalization: forces the variables to have $0$ mean and $1$ standard deviation\n",
        "\n",
        "We will try both to see the effect on the model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZVjkHziyzhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def range_norm(x):\n",
        "    \"\"\"normalization in range [0, 1]\"\"\"\n",
        "    x_min = np.min(x, axis=0)\n",
        "    x_max = np.max(x, axis=0)\n",
        "    x_norm = (x - x_min) / (x_max - x_min)\n",
        "\n",
        "    return x_norm\n",
        "\n",
        "def std_norm(x):\n",
        "    \"\"\"normalization with zero mean and unitary standard deviation\"\"\"\n",
        "    m = np.mean(x, axis=0)\n",
        "    s = np.std(x, axis=0)\n",
        "    x_norm = (x - m) / s\n",
        "    \n",
        "    return x_norm"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORbqtnh-yzhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "57dbcd18-1897-4207-ac13-3fa985927768"
      },
      "source": [
        "data_norm = std_norm(data_orig)\n",
        "data_norm.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Amplitude1</th>\n",
              "      <th>PhaseShift1</th>\n",
              "      <th>Omega1</th>\n",
              "      <th>Beta1</th>\n",
              "      <th>Amplitude2</th>\n",
              "      <th>PhaseShift2</th>\n",
              "      <th>Omega2</th>\n",
              "      <th>Beta2</th>\n",
              "      <th>Amplitude3</th>\n",
              "      <th>PhaseShift3</th>\n",
              "      <th>Omega3</th>\n",
              "      <th>Beta3</th>\n",
              "      <th>Amplitude4</th>\n",
              "      <th>PhaseShift4</th>\n",
              "      <th>Omega4</th>\n",
              "      <th>Beta4</th>\n",
              "      <th>Buckling</th>\n",
              "      <th>Stiffness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "      <td>7.000000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-1.245036e-17</td>\n",
              "      <td>-3.869920e-17</td>\n",
              "      <td>2.895779e-15</td>\n",
              "      <td>5.836601e-17</td>\n",
              "      <td>2.474211e-17</td>\n",
              "      <td>7.930164e-18</td>\n",
              "      <td>-3.578090e-16</td>\n",
              "      <td>-4.694657e-17</td>\n",
              "      <td>4.536054e-17</td>\n",
              "      <td>2.985707e-17</td>\n",
              "      <td>-7.295751e-16</td>\n",
              "      <td>-3.520993e-17</td>\n",
              "      <td>2.791418e-17</td>\n",
              "      <td>-4.044384e-17</td>\n",
              "      <td>-8.792570e-16</td>\n",
              "      <td>2.664535e-17</td>\n",
              "      <td>-3.838200e-17</td>\n",
              "      <td>-1.608237e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "      <td>1.000715e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.406044e+00</td>\n",
              "      <td>-1.728704e+00</td>\n",
              "      <td>-1.727093e+00</td>\n",
              "      <td>-1.727786e+00</td>\n",
              "      <td>-2.381408e+00</td>\n",
              "      <td>-1.726789e+00</td>\n",
              "      <td>-1.730312e+00</td>\n",
              "      <td>-1.726447e+00</td>\n",
              "      <td>-2.455540e+00</td>\n",
              "      <td>-1.729899e+00</td>\n",
              "      <td>-1.726841e+00</td>\n",
              "      <td>-1.732248e+00</td>\n",
              "      <td>-2.438131e+00</td>\n",
              "      <td>-1.726969e+00</td>\n",
              "      <td>-1.728514e+00</td>\n",
              "      <td>-1.727824e+00</td>\n",
              "      <td>-1.642791e+00</td>\n",
              "      <td>-1.854951e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-5.547857e-01</td>\n",
              "      <td>-8.622589e-01</td>\n",
              "      <td>-8.674712e-01</td>\n",
              "      <td>-8.664211e-01</td>\n",
              "      <td>-5.057011e-01</td>\n",
              "      <td>-8.651415e-01</td>\n",
              "      <td>-8.646623e-01</td>\n",
              "      <td>-8.653310e-01</td>\n",
              "      <td>-5.446212e-01</td>\n",
              "      <td>-8.628317e-01</td>\n",
              "      <td>-8.646640e-01</td>\n",
              "      <td>-8.669041e-01</td>\n",
              "      <td>-5.419365e-01</td>\n",
              "      <td>-8.646290e-01</td>\n",
              "      <td>-8.663157e-01</td>\n",
              "      <td>-8.655583e-01</td>\n",
              "      <td>-9.601391e-01</td>\n",
              "      <td>-8.678913e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-1.957726e-02</td>\n",
              "      <td>1.929409e-04</td>\n",
              "      <td>-5.444167e-05</td>\n",
              "      <td>4.196555e-04</td>\n",
              "      <td>5.922758e-02</td>\n",
              "      <td>5.949642e-04</td>\n",
              "      <td>-1.610914e-03</td>\n",
              "      <td>1.248710e-04</td>\n",
              "      <td>-1.522969e-02</td>\n",
              "      <td>-5.759076e-04</td>\n",
              "      <td>-1.620796e-03</td>\n",
              "      <td>-1.752941e-03</td>\n",
              "      <td>7.516864e-03</td>\n",
              "      <td>9.626214e-04</td>\n",
              "      <td>1.945003e-03</td>\n",
              "      <td>-1.396499e-03</td>\n",
              "      <td>5.723826e-01</td>\n",
              "      <td>-1.397617e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.650153e-01</td>\n",
              "      <td>8.653920e-01</td>\n",
              "      <td>8.656300e-01</td>\n",
              "      <td>8.642241e-01</td>\n",
              "      <td>5.272244e-01</td>\n",
              "      <td>8.632861e-01</td>\n",
              "      <td>8.653378e-01</td>\n",
              "      <td>8.651333e-01</td>\n",
              "      <td>4.702517e-01</td>\n",
              "      <td>8.666549e-01</td>\n",
              "      <td>8.661858e-01</td>\n",
              "      <td>8.639324e-01</td>\n",
              "      <td>4.987129e-01</td>\n",
              "      <td>8.626769e-01</td>\n",
              "      <td>8.658753e-01</td>\n",
              "      <td>8.649452e-01</td>\n",
              "      <td>9.309137e-01</td>\n",
              "      <td>7.918783e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.381366e+00</td>\n",
              "      <td>1.731534e+00</td>\n",
              "      <td>1.730448e+00</td>\n",
              "      <td>1.731724e+00</td>\n",
              "      <td>2.483459e+00</td>\n",
              "      <td>1.728306e+00</td>\n",
              "      <td>1.727090e+00</td>\n",
              "      <td>1.726389e+00</td>\n",
              "      <td>2.426293e+00</td>\n",
              "      <td>1.731037e+00</td>\n",
              "      <td>1.728796e+00</td>\n",
              "      <td>1.729435e+00</td>\n",
              "      <td>2.455543e+00</td>\n",
              "      <td>1.726643e+00</td>\n",
              "      <td>1.727207e+00</td>\n",
              "      <td>1.728611e+00</td>\n",
              "      <td>1.620255e+00</td>\n",
              "      <td>3.167960e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Amplitude1   PhaseShift1  ...      Buckling     Stiffness\n",
              "count  7.000000e+02  7.000000e+02  ...  7.000000e+02  7.000000e+02\n",
              "mean  -1.245036e-17 -3.869920e-17  ... -3.838200e-17 -1.608237e-15\n",
              "std    1.000715e+00  1.000715e+00  ...  1.000715e+00  1.000715e+00\n",
              "min   -2.406044e+00 -1.728704e+00  ... -1.642791e+00 -1.854951e+00\n",
              "25%   -5.547857e-01 -8.622589e-01  ... -9.601391e-01 -8.678913e-01\n",
              "50%   -1.957726e-02  1.929409e-04  ...  5.723826e-01 -1.397617e-01\n",
              "75%    4.650153e-01  8.653920e-01  ...  9.309137e-01  7.918783e-01\n",
              "max    2.381366e+00  1.731534e+00  ...  1.620255e+00  3.167960e+00\n",
              "\n",
              "[8 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL3mX63XyzhT",
        "colab_type": "text"
      },
      "source": [
        "Now we can split the data into training and test set. The two sets have been generate independently during the DOE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy149NwNyzhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "ba3fbcd7-912b-4a96-8c40-6cf85d9cd6fb"
      },
      "source": [
        "X = data_norm.drop(['Buckling', 'Stiffness'], axis=1).values\n",
        "Y = data_norm[['Buckling','Stiffness']].values\n",
        "\n",
        "# Train set\n",
        "_X_train = X[:train_smp, :]\n",
        "_Y_train = Y[:train_smp]\n",
        "\n",
        "# Test set\n",
        "X_test = X[train_smp:, :]\n",
        "Y_test = Y[train_smp:]\n",
        "\n",
        "print('- - - - -')\n",
        "print('Problem info:')\n",
        "print('- - - - -')\n",
        "print(\"X_train : {}\".format(_X_train.shape))\n",
        "print(\"Y_train : {}\".format(_Y_train.shape))\n",
        "print(\"X_test : {}\".format(X_test.shape))\n",
        "print(\"Y_test : {}\".format(Y_test.shape))\n",
        "print('- - - - -')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- - - - -\n",
            "Problem info:\n",
            "- - - - -\n",
            "X_train : (560, 16)\n",
            "Y_train : (560, 2)\n",
            "X_test : (140, 16)\n",
            "Y_test : (140, 2)\n",
            "- - - - -\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--wM6mi5sU75",
        "colab_type": "text"
      },
      "source": [
        "We can now split the training set into train and val. In this way the validation set will be used to monitoring the overfitting/underfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kCLvQ1TsT9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(_X_train, _Y_train, test_size=0.2, random_state=seed)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ngXLJgnf3zs",
        "colab_type": "text"
      },
      "source": [
        "At this point we can generate the iterable data sets for Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3haXjC9f3UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# just for the training set\n",
        "batch = 32\n",
        "\n",
        "def _init_fn(worker_id):\n",
        "    np.random.seed(int(seed))\n",
        "    \n",
        "train_dataset = Data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).float())\n",
        "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=batch, shuffle=True, num_workers=0, pin_memory=True, worker_init_fn=_init_fn)\n",
        "\n",
        "val_dataset = Data.TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(Y_val).float())\n",
        "val_loader = Data.DataLoader(dataset=val_dataset, batch_size=X_val.shape[0], shuffle=True, num_workers=0, pin_memory=True, worker_init_fn=_init_fn)\n",
        "\n",
        "test_dataset = Data.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test).float())\n",
        "test_loader = Data.DataLoader(dataset=test_dataset, batch_size=X_test.shape[0], shuffle=True, num_workers=0, pin_memory=True, worker_init_fn=_init_fn)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7O7AIIoyzhU",
        "colab_type": "text"
      },
      "source": [
        "## **Neural network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyx3cytYfs7E",
        "colab_type": "text"
      },
      "source": [
        "First define network class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aMiO2DUfrIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLPNN(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super(MLPNN, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(D_in, H)\n",
        "        self.linear2 = torch.nn.Linear(H, H//2)\n",
        "        self.linear3 = torch.nn.Linear(H//2, H)\n",
        "        self.linear4 = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_relu = self.linear1(x).clamp(min=0)\n",
        "        h_relu = self.linear2(h_relu).clamp(min=0)\n",
        "        h_relu = self.linear3(h_relu).clamp(min=0)\n",
        "        y_pred = self.linear4(h_relu)\n",
        "        return y_pred"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cyx2vNti_z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=30, delta=1e-3, path='checkpoint.pt'):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        if self.val_loss_min > val_loss:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            torch.save(model.state_dict(), self.path)\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibkHXkYKmXs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "a9eb4f26-5ac1-4758-a7f7-b6d333cf56c4"
      },
      "source": [
        "n_x = X_train.shape[1]\n",
        "n_y = Y_train.shape[1]\n",
        "D_in, H, D_out = n_x, 8, n_y\n",
        "\n",
        "modelMLP = MLPNN(D_in, H, D_out)\n",
        "\n",
        "epochs = 1\n",
        "lr = 1e-3\n",
        "\n",
        "is_optimizing = True\n",
        "\n",
        "if(os.path.isfile('net_weights/weights_NN') and is_optimizing==False):\n",
        "    modelMLP.load_state_dict(torch.load('net_weights/weights_NN'))\n",
        "    print(modelMLP.eval())\n",
        "else:\n",
        "    criterion = torch.nn.MSELoss(reduction='mean') \n",
        "    optimizer = torch.optim.Adam(modelMLP.parameters(), lr=lr)\n",
        "    train_loss = []\n",
        "    for epoch in range(epochs):\n",
        "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
        "            print(batch_x[0, :])\n",
        "            y_pred = modelMLP(batch_x)\n",
        "            loss = criterion(y_pred, batch_y)\n",
        "            train_loss.append(loss.item())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            modelMLP.eval()\n",
        "            for step, (val_x, val_y) in enumerate(val_loader):\n",
        "                val_pred = modelMLP(val_x)\n",
        "                loss_val = criterion(val_pred, val_y)\n",
        "            modelMLP.train()\n",
        "            print(\"Iteration: \", epoch, \" Loss: \", loss.item(), \" Val loss: \", loss_val.item())\n",
        "    torch.save(modelMLP.state_dict(), 'weights_NN')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.1854, -0.5917, -1.2195, -0.5788,  2.2205,  1.3090,  0.5111,  1.6995,\n",
            "         0.6404, -0.8929,  1.1035, -1.3761, -0.5442, -1.4146, -1.5362,  1.3427])\n",
            "tensor([ 0.0678, -0.5028, -0.4764, -0.4828, -0.1579, -0.4769,  0.1907, -1.0244,\n",
            "        -0.3277,  0.3701,  0.2184,  0.6548, -0.7940,  1.1124, -0.8919, -1.1872])\n",
            "tensor([-0.1353,  1.5654,  1.0358,  0.4201, -0.2290, -0.1612,  1.0948, -0.9484,\n",
            "         0.3138,  1.3413, -0.2129,  0.2227, -0.8676,  1.0515,  0.2964, -1.1386])\n",
            "tensor([ 1.1479,  1.0642,  0.0675, -1.2585,  1.7774,  1.3830, -0.1991,  1.7188,\n",
            "        -0.1319,  1.6125,  1.3997,  0.5878, -0.0870, -1.1706,  0.0539,  1.3777])\n",
            "tensor([-1.0677, -0.1865,  0.1714, -1.1672, -0.1349,  0.2420,  0.2877, -0.2812,\n",
            "        -0.8078,  1.5600, -1.2557,  1.5817,  1.9076,  1.5032, -1.4583,  1.0431])\n",
            "tensor([-0.2395,  0.7743, -0.0070,  1.7203, -0.0719,  0.8165,  1.4673,  0.6797,\n",
            "        -0.1342,  1.3806,  1.4932,  0.6584, -1.0418, -1.6530, -0.8728, -0.2634])\n",
            "tensor([-0.2801, -0.2190,  1.6941, -1.0313,  0.4700, -0.2358,  1.0706, -1.0692,\n",
            "         0.0848,  1.3665,  0.9996,  0.1735, -2.2845,  0.0339, -1.0114, -1.6275])\n",
            "tensor([ 0.0655,  0.6382, -1.2403, -0.7679,  0.3287, -0.3427,  1.0048, -0.8831,\n",
            "        -1.4373,  1.0122,  0.7138,  1.3528, -1.9564,  1.3877, -1.0149, -0.6562])\n",
            "tensor([ 1.7603,  1.4355, -1.5625,  0.9507, -0.0619, -1.5399, -0.4173,  0.5769,\n",
            "         1.4306, -0.4306,  0.3361, -1.2974, -0.0539,  1.7072,  1.2110,  1.4867])\n",
            "tensor([-0.5981,  1.3388, -1.4603,  0.4879, -0.1151, -1.5836,  0.2288,  0.7929,\n",
            "        -0.2305, -0.0870,  0.5873, -0.6289,  0.4539,  0.1163,  0.8992,  1.5232])\n",
            "tensor([ 0.1541,  0.4276, -1.1070, -1.2161,  0.1300, -0.6939,  1.4188, -0.0470,\n",
            "        -0.4901,  0.5093, -1.7268,  0.1913,  0.3098,  1.2198,  1.3548,  1.3272])\n",
            "tensor([-0.0472, -0.1328,  1.2385,  1.6628, -0.2943,  0.0305, -0.3359,  1.2687,\n",
            "        -0.5485,  1.4771, -1.2921, -0.7261, -1.5958, -1.0136,  0.8438,  1.3987])\n",
            "tensor([ 0.1364,  0.4979,  1.1536,  0.6901,  1.5070,  0.8598, -0.7638,  0.8244,\n",
            "         0.3118, -1.4780, -0.2459, -0.0699, -0.2315, -1.3401,  0.8732,  0.8024])\n",
            "tensor([ 0.2212,  0.0667,  1.0583,  0.8554, -0.7435,  1.4557, -0.8382, -1.6646,\n",
            "        -0.1129, -1.1139,  1.0134, -0.1577,  0.0863, -0.2859, -0.8278, -1.3699])\n",
            "Iteration:  0  Loss:  0.9772776961326599  Val loss:  0.9213021993637085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xrNCyKayzha",
        "colab_type": "text"
      },
      "source": [
        "Let's define some important metrics used to evaluate the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uaGMMmokvr70",
        "colab": {}
      },
      "source": [
        "def r_2(y_true, y_pred):\n",
        "    num = np.sum(((y_true - y_pred) ** 2), 0)\n",
        "    den = np.sum((y_true - np.mean(y_true, 0) ** 2), 0)\n",
        "    return np.mean(1 - num / den)\n",
        "\n",
        "def rmae(y_true, y_pred):\n",
        "    max_err = np.amax(abs(y_true - y_pred), 0)\n",
        "    std = ((0.5 * np.sum((y_pred - np.mean(y_true, 0)) ** 2,0)) ** 0.5)\n",
        "    return np.mean(max_err / std)\n",
        "    \n",
        "def raae(y_true, y_pred):\n",
        "    num = np.sum(abs(y_true - y_pred), 0)\n",
        "    den = std = ((0.5 * np.sum((y_pred - np.mean(y_true, 0)) ** 2,0)) ** 0.5) * np.size(y_true, 0)\n",
        "    return np.mean(num / den)\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return np.mean((abs(y_true - y_pred) / y_true) * 100)\n",
        "\n",
        "def mpe(y_true, y_pred):\n",
        "    val_max = np.max((abs(y_true - y_pred) / y_true) * 100)\n",
        "    idx = np.argmax(val_max)\n",
        "    return val_max, idx\n",
        "\n",
        "def mse(y_pred, y_true):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y_true))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzLIhhxJyzhc",
        "colab_type": "text"
      },
      "source": [
        "In the cell below we will define the architecture of our network. The ANN will be composed by $3$ hidden layers and $1$ output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XcTi3iu4vx21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "9cd8dbc5-4450-4be7-db4a-ededc4a5cb0e"
      },
      "source": [
        "def build_model(in_dim, out_dim, l_arc, l_2, w_init, b_init, learning_rate):\n",
        "    model = keras.Sequential([\n",
        "      layers.Dense(l_arc[0][0], activation=l_arc[0][1], input_shape=[in_dim],\n",
        "                    kernel_initializer=w_init, bias_initializer=b_init,\n",
        "                   kernel_regularizer=l2(l=l_2)),\n",
        "      layers.Dense(l_arc[1][0], activation=l_arc[1][1], \n",
        "                    kernel_initializer=w_init, bias_initializer=b_init,\n",
        "                   kernel_regularizer=l2(l_2)),\n",
        "      layers.Dense(l_arc[2][0], activation=l_arc[1][1],\n",
        "                    kernel_initializer=w_init, bias_initializer=b_init,\n",
        "                   kernel_regularizer=l2(l_2)),\n",
        "      layers.Dense(out_dim,\n",
        "                    kernel_initializer=w_init, bias_initializer=b_init,\n",
        "                  kernel_regularizer=l2(l_2))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Nadam(lr=learning_rate)\n",
        "\n",
        "    model.compile(loss=mse, optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "neural_net = build_model(input_dim, output_dim, layers_architecture, l_2,\n",
        "                         W_initializer, b_initializer, learning_rate)\n",
        "\n",
        "neural_net.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-25-635935f1dd42>, line 15)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-635935f1dd42>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    optimizer = tf.keras.optimizers.Nadam(lr=learning_rate)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "StDFJo7Wvzt1",
        "colab": {}
      },
      "source": [
        "history = neural_net.fit(\n",
        "  x_train.values, y_train.values, batch_size=BATCH_SIZE, shuffle=True,\n",
        "  epochs=EPOCHS, validation_data=(x_val.values, y_val.values), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q-x7Iedwv1Mc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "c14c96d2-9c30-433d-b756-26c2efade6be"
      },
      "source": [
        "epochs = [i for i in range(EPOCHS)]\n",
        "plt.axes(ylim=(0., 0.015))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f613d8b90f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8DAzs8wcHmZmlpnDw8zMMnN4mJlZZv8ffZgQgH4kty8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qTcuaCycv7gD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "b43eeb58-7cfc-43ee-e7ad-11619f27814e"
      },
      "source": [
        "prediction_train = neural_net.predict(x_train.values)\n",
        "prediction_val = neural_net.predict(x_val.values)\n",
        "\n",
        "# metrics\n",
        "r2_train = r_2(y_train.values, prediction_train)\n",
        "rmae_train = rmae(y_train.values, prediction_train)\n",
        "raae_train = raae(y_train.values, prediction_train)\n",
        "\n",
        "PREDICTION_TRAIN = recover_output(prediction_train, y_min_max)\n",
        "mape_train = mape(Y_train.values, PREDICTION_TRAIN)\n",
        "mpe_train, _ = mpe(Y_train.values, PREDICTION_TRAIN)\n",
        "\n",
        "r2_val = r_2(y_val.values, prediction_val)\n",
        "rmae_val = rmae(y_val.values, prediction_val)\n",
        "raae_val = raae(y_val.values, prediction_val)\n",
        "\n",
        "PREDICTION_VAL = recover_output(prediction_val, y_min_max)\n",
        "mape_val = mape(Y_val.values, PREDICTION_VAL)\n",
        "mpe_val, _ = mpe(Y_val.values, PREDICTION_VAL)\n",
        "\n",
        "metrics = {'R2': [r2_train, r2_val],\n",
        "           'RMAE': [rmae_train, rmae_val],\n",
        "           'RAAE': [raae_train, rmae_val],\n",
        "           'MAPE': [mape_train, mape_val],\n",
        "           'MPE': [mpe_train, mpe_val]}\n",
        "metrics_df = pd.DataFrame(metrics, index=['train', 'val'])\n",
        "metrics_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>RMAE</th>\n",
              "      <th>RAAE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>MPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>0.988971</td>\n",
              "      <td>0.099963</td>\n",
              "      <td>0.029417</td>\n",
              "      <td>4.481064</td>\n",
              "      <td>24.141277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>0.972480</td>\n",
              "      <td>0.252280</td>\n",
              "      <td>0.252280</td>\n",
              "      <td>6.066769</td>\n",
              "      <td>33.026807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             R2      RMAE      RAAE      MAPE        MPE\n",
              "train  0.988971  0.099963  0.029417  4.481064  24.141277\n",
              "val    0.972480  0.252280  0.252280  6.066769  33.026807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2fg9BLsKMjI5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e4bc8840-c2a7-4040-e024-7e7fb0b979cb"
      },
      "source": [
        "prediction_test = neural_net.predict(x_test.values)\n",
        "\n",
        "r2_test = r_2(y_test.values, prediction_test)\n",
        "rmae_test= rmae(y_test.values, prediction_test)\n",
        "raae_test = raae(y_test.values, prediction_test)\n",
        "\n",
        "PREDICTION_TEST = recover_output(prediction_test, y_min_max)\n",
        "mape_test = mape(Y_test.values, PREDICTION_TEST)\n",
        "mpe_test, _ = mpe(Y_test.values, PREDICTION_TEST)\n",
        "\n",
        "metrics = {'R2': [r2_train, r2_val, r2_test],\n",
        "           'RMAE': [rmae_train, rmae_val, rmae_test],\n",
        "           'RAAE': [raae_train, raae_val, raae_test],\n",
        "           'MAPE': [mape_train, mape_val, mape_test],\n",
        "           'MPE': [mpe_train, mpe_val, mpe_test]}\n",
        "metrics_df = pd.DataFrame(metrics, index=['train', 'val', 'test'])\n",
        "metrics_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>RMAE</th>\n",
              "      <th>RAAE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>MPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>0.988971</td>\n",
              "      <td>0.099963</td>\n",
              "      <td>0.029417</td>\n",
              "      <td>4.481064</td>\n",
              "      <td>24.141277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>0.972480</td>\n",
              "      <td>0.252280</td>\n",
              "      <td>0.069448</td>\n",
              "      <td>6.066769</td>\n",
              "      <td>33.026807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>0.970069</td>\n",
              "      <td>0.282665</td>\n",
              "      <td>0.121426</td>\n",
              "      <td>7.100456</td>\n",
              "      <td>23.904591</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             R2      RMAE      RAAE      MAPE        MPE\n",
              "train  0.988971  0.099963  0.029417  4.481064  24.141277\n",
              "val    0.972480  0.252280  0.069448  6.066769  33.026807\n",
              "test   0.970069  0.282665  0.121426  7.100456  23.904591"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}