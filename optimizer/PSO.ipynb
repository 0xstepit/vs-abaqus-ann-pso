{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTh7XIZJCX-i"
   },
   "source": [
    "# **OPTIMIZATION OF VARIABLE STIFFNESS CYLINDRICAL SHELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhbFr4zAM3Af"
   },
   "source": [
    "In this notebook the optimized neural network will be used for the optimization of the fibers path parameters in order to achieve the maximum buckling load. To this end a bio-inspired metaheuristic algorithm, named PSO, will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9h3x9SSQOm0a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import pyDOE\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Matplotlib spec\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Palatino']}) # Palatino font\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed=seed)\n",
    "torch.manual_seed(seed=seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEbYJLPTPHmp"
   },
   "source": [
    "We need to import the normalization variables in order to normalize the particles position and recover the output of the networks. These normalization variables must be the same used during the training of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ODKOMqsoWMBA",
    "outputId": "0bcb6ed3-f803-42ee-da4d-afaace2e5d3a"
   },
   "outputs": [],
   "source": [
    "# Modify parameter to choose the output folder to consider\n",
    "load_case = 'torsion'\n",
    "stacking_sequence = 'symmetric_balanced'\n",
    "data_set = '8x'\n",
    "fiber_path = 'harmlin'\n",
    "\n",
    "input_folder = '../metamodel/' + load_case + '/' + stacking_sequence + '/' + data_set + '/' + fiber_path + '/'\n",
    "\n",
    "x_norm = pd.read_csv(input_folder + 'X_bounds.csv', sep=\",\", index_col=0)\n",
    "y_norm = pd.read_csv(input_folder + 'Y_bounds.csv', sep=\",\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E8yp7LJZaZI5"
   },
   "source": [
    "Now we have to import some function previously defined in the metamodel notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_norm(x, x_min=None, x_max=None):\n",
    "    \"\"\" Normalization in range [0, 1] \"\"\"\n",
    "    if x_min is None and x_max is None:\n",
    "        x_min = np.min(x, axis=0)\n",
    "        x_max = np.max(x, axis=0)\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "    return x_norm, x_min, x_max\n",
    "\n",
    "def std_norm(x, m=None, s=None):\n",
    "    \"\"\" Normalization with zero mean and unitary standard deviation \"\"\"\n",
    "    if m is None and s is None:\n",
    "        m = np.mean(x, axis=0)\n",
    "        s = np.std(x, axis=0)\n",
    "    x_norm = (x - m) / s\n",
    "    \n",
    "    return x_norm, m, s\n",
    "\n",
    "def reverse_range_norm(x_norm, x_min, x_max):\n",
    "    \"\"\" Inverse of normalization in range [0, 1] \"\"\"\n",
    "    x = x_min +  x_norm * (x_max - x_min)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know how many free plies we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Radius</th>\n",
       "      <th>MaxCurvature</th>\n",
       "      <th>MeshSize</th>\n",
       "      <th>Plies</th>\n",
       "      <th>EffectivePlies</th>\n",
       "      <th>Symmetric</th>\n",
       "      <th>Balanced</th>\n",
       "      <th>AnglesFunction</th>\n",
       "      <th>LoadCase</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Value</td>\n",
       "      <td>705</td>\n",
       "      <td>300</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>harmlin</td>\n",
       "      <td>torsion</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Height  Radius  MaxCurvature  MeshSize  Plies  EffectivePlies  \\\n",
       "Value     705     300      0.001575        10      8               2   \n",
       "\n",
       "       Symmetric  Balanced AnglesFunction LoadCase  Train  Test  \n",
       "Value       True      True        harmlin  torsion    512   128  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = pd.read_csv(input_folder + 'model_info.csv', sep=\",\")\n",
    "info.index = ['Value']\n",
    "eff_plies = int(info['EffectivePlies'].values)\n",
    "h = info['Height'].values\n",
    "mesh_size = info['MeshSize'].values\n",
    "k_max = info['MaxCurvature'].values\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to recover the boundaries used during the design of experiments in order to be able to define the deisign space in which search for an optimum configuration. The dimension of the space in which each particle lives is given by the number of variables in each ply and the number of free plies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries_df = pd.read_csv(input_folder + 'features_min_max.csv', sep=',')\n",
    "boundaries_df.index = ['min', 'max']\n",
    "boundaries = boundaries_df.to_numpy()\n",
    "#boundaries = np.tile(boundaries_df.to_numpy(), 2)\n",
    "interval = boundaries[None, 1, :] - boundaries[None, 0, :]\n",
    "min_boundaries = boundaries[None, 0, :]\n",
    "max_boundaries = boundaries[None, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bounds_df = pd.read_csv(input_folder + 'X_bounds.csv', sep=',', index_col=0)\n",
    "y_bounds_df = pd.read_csv(input_folder + 'Y_bounds.csv', sep=',', index_col=0)\n",
    "x_bounds = x_bounds_df.to_numpy()\n",
    "y_bounds = y_bounds_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to import the network architecture and instanciate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in, H, D_out = 8, 64, 2\n",
    "p = 0.2\n",
    "\n",
    "class FFNN(torch.nn.Module):\n",
    "    \"\"\" Implementation of FeedForward Neural Network \"\"\"\n",
    "    def __init__(self, D_in, H, D_out, p):\n",
    "        super(FFNN, self).__init__()\n",
    "        # First hidden layer\n",
    "        self.W_1 = Parameter(init.xavier_normal_(torch.Tensor(H, D_in)))\n",
    "        self.b_1 = Parameter(init.constant_(torch.Tensor(H), 0))\n",
    "        # Second hidden layer\n",
    "        self.W_2 = Parameter(init.xavier_normal_(torch.Tensor(H, H)))\n",
    "        self.b_2 = Parameter(init.constant_(torch.Tensor(H), 0))\n",
    "        # Third hidden layer\n",
    "        #self.W_3 = Parameter(init.xavier_normal_(torch.Tensor(H, H)))\n",
    "        #self.b_3 = Parameter(init.constant_(torch.Tensor(H), 0))\n",
    "        # Output layer\n",
    "        self.W_4 = Parameter(init.xavier_normal_(torch.Tensor(D_out, H)))\n",
    "        self.b_4 = Parameter(init.constant_(torch.Tensor(D_out), 0))\n",
    "        \n",
    "        # define activation function in constructor\n",
    "        self.activation_1 = torch.nn.ReLU()\n",
    "        self.activation_2 = torch.nn.ReLU()\n",
    "        #self.activation_3 = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.linear(x, self.W_1, self.b_1)\n",
    "        x = self.activation_1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.linear(x, self.W_2, self.b_2)\n",
    "        x = self.activation_2(x)\n",
    "        x = self.dropout(x)\n",
    "        #x = F.linear(x, self.W_3, self.b_3)\n",
    "        #x = self.activation_3(x)\n",
    "        #x = self.dropout(x)\n",
    "        pred = F.linear(x, self.W_4, self.b_4)\n",
    "        return pred\n",
    "    \n",
    "model = FFNN(D_in, H, D_out, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(input_folder + 'weights_NN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if the weights are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_1 Parameter containing:\n",
      "tensor([[-1.0844e-01, -4.9057e-01, -4.6628e-01,  6.9210e-01, -2.3332e-01,\n",
      "          4.2882e-01, -4.1004e-01, -1.8674e-01],\n",
      "        [-1.4891e-01, -3.9336e-01, -9.4734e-02,  5.2422e-02,  1.7628e-01,\n",
      "          2.3287e-01, -8.9333e-03,  3.8331e-01],\n",
      "        [-1.8496e-01,  2.4584e-02,  2.1688e-02,  3.7966e-02,  5.9815e-02,\n",
      "         -5.8522e-01, -5.1259e-01,  1.1237e-01],\n",
      "        [ 1.1920e-03, -5.3885e-03,  5.2022e-03, -2.2404e-03,  2.4978e-02,\n",
      "         -2.0544e-02,  2.3576e-02, -6.3236e-01],\n",
      "        [ 7.2022e-02, -5.1027e-02, -2.5911e-02,  5.7195e-01, -5.0238e-02,\n",
      "          6.3549e-03,  6.9255e-03, -9.6424e-03],\n",
      "        [-8.7163e-02,  1.0295e-01, -1.1280e-01, -2.4809e-01,  6.9280e-02,\n",
      "          3.9446e-01, -5.7644e-01, -1.3134e-01],\n",
      "        [-5.4915e-01,  1.8107e-01,  3.1066e-01, -4.0122e-02,  3.0949e-02,\n",
      "         -7.8460e-02,  1.0198e-02, -1.1879e-01],\n",
      "        [ 1.3140e-02,  5.5321e-03,  1.2650e-02,  7.3111e-01, -3.6382e-02,\n",
      "         -2.8615e-02, -1.0237e-02, -2.4332e-02],\n",
      "        [ 2.7867e-02,  4.3903e-02,  5.0828e-03,  3.1196e-01, -1.5185e-01,\n",
      "          1.3220e-01,  9.0371e-02,  2.8901e-01],\n",
      "        [-2.3288e-01, -1.5710e-01, -2.6328e-01, -2.2125e-01, -1.4394e-01,\n",
      "          5.7349e-01, -3.9494e-01,  5.7261e-01],\n",
      "        [-1.2140e-02, -5.0333e-04,  8.5482e-03, -6.9222e-01,  7.8181e-02,\n",
      "          1.0093e-02, -9.4183e-03,  1.4308e-02],\n",
      "        [ 3.0464e-01,  5.2449e-01, -7.4451e-02, -1.5828e-01, -1.2839e-01,\n",
      "         -2.1625e-01,  7.8812e-02,  4.2669e-02],\n",
      "        [ 2.6085e-01, -1.8634e-01, -1.3076e-01,  1.7110e-01, -7.7619e-01,\n",
      "         -2.2135e-01, -1.7079e-03,  2.9317e-01],\n",
      "        [-1.0480e-02, -3.2760e-02, -4.5917e-03, -1.9695e-03, -8.1825e-03,\n",
      "         -2.2551e-02, -9.3070e-03, -7.8803e-01],\n",
      "        [ 5.1877e-01, -5.1291e-01,  2.3426e-01,  1.1469e-01, -1.7116e-01,\n",
      "          5.6418e-02, -1.8112e-01, -2.4057e-03],\n",
      "        [ 1.5666e-02, -1.8349e-03,  2.1933e-02, -8.1866e-03,  8.8873e-03,\n",
      "         -3.8231e-02, -1.7846e-02,  6.1761e-01],\n",
      "        [-2.4814e-01,  1.0727e-01,  3.6851e-02,  1.5521e-01,  7.0094e-02,\n",
      "         -4.3083e-02,  3.8171e-01, -2.8680e-03],\n",
      "        [ 1.7535e-02, -1.1089e-02, -1.2469e-02,  7.2036e-01,  2.1808e-02,\n",
      "         -4.3915e-03, -3.3395e-02, -2.1680e-02],\n",
      "        [ 4.4016e-02, -9.6052e-03,  4.1551e-03,  8.8652e-01, -1.1954e-02,\n",
      "         -1.9361e-02, -2.2673e-02, -6.6510e-04],\n",
      "        [-1.7163e-01, -2.4287e-02, -7.4443e-01,  2.3707e-02, -4.6964e-02,\n",
      "          1.4123e-01, -1.6278e-01, -3.3166e-03],\n",
      "        [ 1.2856e-01, -1.3241e-01,  1.7343e-01, -4.4937e-01,  5.0444e-01,\n",
      "         -3.5566e-01,  3.8307e-02, -1.9195e-01],\n",
      "        [-5.3341e-03,  1.4626e-02, -2.4461e-02,  4.6804e-02,  1.8781e-02,\n",
      "         -4.5524e-02,  6.2318e-02, -1.7648e+00],\n",
      "        [-7.3661e-02, -1.4683e-01, -5.2092e-01,  3.4310e-02, -4.1813e-03,\n",
      "          1.7898e-01,  2.5288e-01,  3.1542e-01],\n",
      "        [-7.0800e-01, -1.8801e-01,  3.3306e-01,  2.6298e-02, -1.8875e-01,\n",
      "         -2.2749e-03,  4.2050e-02, -1.2990e-01],\n",
      "        [ 6.7781e-03,  2.1143e-03,  1.5522e-02, -1.0262e-02,  2.0047e-02,\n",
      "         -4.0300e-02, -1.5258e-02,  7.2497e-01],\n",
      "        [ 3.5062e-04, -7.4771e-03,  1.3226e-02,  8.7713e-01,  4.4254e-02,\n",
      "          1.3752e-02, -3.5190e-03, -2.0116e-01],\n",
      "        [ 2.7619e-01, -1.4189e-01,  2.5657e-01,  2.7069e-01, -4.8554e-01,\n",
      "          1.8988e-01, -5.6985e-02,  1.7531e-01],\n",
      "        [ 3.5023e-02,  8.9313e-02, -1.2721e-01,  1.3398e-01,  1.8522e-01,\n",
      "         -1.7377e-01, -3.2339e-01,  2.6656e-01],\n",
      "        [-1.7246e-02, -9.1714e-03,  7.8256e-03, -5.8404e-02,  5.5100e-03,\n",
      "          1.3484e-03, -2.5005e-03, -1.3705e+00],\n",
      "        [ 2.4685e-01, -2.0182e-02, -1.3812e-01,  1.3410e-01, -8.5874e-01,\n",
      "         -1.6122e-03,  3.3256e-01, -1.5802e-01],\n",
      "        [-5.7846e-01, -3.5988e-01,  3.7208e-02, -7.2953e-01, -6.3505e-02,\n",
      "         -1.1108e-03, -1.5298e-01, -2.0105e-01],\n",
      "        [-7.1637e-02,  4.2091e-02,  2.5132e-02, -5.2019e-01,  8.1150e-02,\n",
      "          1.0033e-03,  2.4940e-02,  6.1611e-01],\n",
      "        [ 4.2385e-05,  2.6666e-05,  3.4214e-05, -1.9625e-05, -3.6069e-05,\n",
      "         -2.6943e-05,  2.3318e-05, -2.1698e-05],\n",
      "        [-5.6526e-02,  3.4733e-02,  6.7802e-03, -1.8144e-01, -1.2912e-02,\n",
      "         -2.5097e-02,  2.9677e-02,  9.8578e-01],\n",
      "        [-7.7475e-06,  5.9301e-06, -1.8844e-06,  1.0501e-05,  2.2919e-05,\n",
      "          1.1559e-05,  4.7148e-06, -1.2189e-05],\n",
      "        [-1.4510e-01,  9.7375e-02,  1.7491e-01, -1.0011e-01, -1.0493e+00,\n",
      "          8.9976e-02,  4.2141e-01,  6.3543e-02],\n",
      "        [ 2.3625e-01,  2.0107e-01,  1.5814e-02, -8.8970e-01,  1.8992e-02,\n",
      "         -1.4729e-02,  2.4035e-02, -4.9901e-01],\n",
      "        [ 1.3358e-02, -1.0489e-02, -4.4734e-03, -1.0966e-02, -1.2194e-02,\n",
      "         -1.4186e-02,  7.7175e-03, -6.7784e-01],\n",
      "        [ 4.4299e-02, -1.2579e-01, -8.2714e-02,  1.1046e+00, -9.9921e-02,\n",
      "         -1.1693e-02, -1.0037e-01, -9.6645e-02],\n",
      "        [-3.9751e-01,  3.4425e-01, -1.5810e-01, -9.1850e-01,  6.2328e-01,\n",
      "          1.5106e-04, -3.1949e-01,  9.9856e-02],\n",
      "        [-1.0390e-01, -1.1792e-03, -1.9893e-01, -7.0709e-02,  5.8567e-02,\n",
      "          3.2614e-01,  2.0391e-01, -8.0878e-02],\n",
      "        [-3.3268e-01,  1.2249e-01, -2.7809e-02,  1.1352e-01,  3.5619e-01,\n",
      "         -1.6145e-01,  1.4630e-01, -5.9135e-03],\n",
      "        [ 2.2202e-01,  3.6265e-01, -1.2008e-01, -2.1518e-01, -2.5427e-01,\n",
      "         -5.1642e-02, -1.2405e-01,  3.8521e-01],\n",
      "        [ 1.1141e-01, -2.4619e-01, -8.2764e-01, -2.4855e-01,  4.2161e-01,\n",
      "          3.6868e-01, -3.6010e-02, -3.3215e-01],\n",
      "        [ 5.1238e-02, -2.5498e-02, -3.8415e-02,  9.7346e-01, -4.9586e-02,\n",
      "         -4.3489e-02, -4.6563e-02,  5.6522e-02],\n",
      "        [ 1.0806e-01, -4.6786e-02,  1.1394e-02, -8.7110e-01,  1.6838e-02,\n",
      "         -2.7872e-02, -4.1876e-02, -4.1077e-01],\n",
      "        [ 4.8652e-03,  4.2394e-03,  8.6441e-03, -7.9896e-03,  8.6882e-03,\n",
      "         -2.8322e-02, -4.9992e-03,  8.3308e-01],\n",
      "        [-2.9328e-02, -2.9241e-02,  7.1670e-03, -1.9381e+00,  4.9141e-02,\n",
      "          2.9948e-02,  2.4500e-02,  1.0333e-01],\n",
      "        [ 1.6407e-02,  3.6978e-02,  4.1935e-02,  6.0886e-01,  4.6733e-02,\n",
      "         -6.5504e-02,  4.5734e-02, -4.7528e-02],\n",
      "        [ 7.3859e-02,  4.3628e-03,  1.3842e-02, -6.3777e-01,  1.2565e-02,\n",
      "         -1.0053e-02, -7.6583e-03, -1.3661e-02],\n",
      "        [ 3.4180e-02,  1.2163e-03,  3.8031e-02, -1.2720e+00,  4.3714e-04,\n",
      "         -1.4935e-01, -4.1294e-02, -9.7191e-02],\n",
      "        [ 4.8948e-01, -2.5928e-01, -1.0032e-01,  2.0506e-01,  1.0472e-02,\n",
      "         -1.2401e-01,  1.9718e-01,  1.8678e-01],\n",
      "        [-1.2365e-01,  5.6998e-02,  2.2850e-02,  6.7332e-01,  2.1596e-02,\n",
      "          7.4934e-02, -4.2624e-04, -1.4507e-02],\n",
      "        [-5.5676e-02, -4.0404e-02,  7.1155e-02,  2.6401e-01,  1.0655e-01,\n",
      "         -5.5856e-03,  1.0473e-02, -1.3387e-01],\n",
      "        [ 8.2770e-02,  1.1406e-01, -3.0749e-01,  1.2977e-01,  2.2413e-02,\n",
      "          3.0460e-01, -2.0829e-01, -2.1471e-02],\n",
      "        [ 2.4317e-01, -2.6288e-02,  9.2921e-02, -1.0394e+00,  2.3064e-01,\n",
      "         -5.1541e-02,  2.9187e-01, -3.3564e-01],\n",
      "        [-2.2131e-01,  8.3428e-02,  2.0617e-02, -2.7853e-01,  5.1261e-01,\n",
      "         -2.2280e-01, -1.4498e-01,  2.5384e-01],\n",
      "        [ 2.5073e-02, -1.4383e-03,  3.0116e-02,  6.9193e-02,  7.6774e-02,\n",
      "          6.4241e-03, -2.0786e-02,  6.8348e-01],\n",
      "        [-4.3917e-01, -6.0662e-01, -2.1586e-01,  1.6908e-02,  2.9456e-01,\n",
      "          3.1355e-02,  2.7211e-02,  3.6422e-02],\n",
      "        [-1.6864e-01,  2.4105e-01,  1.1299e-01,  1.4254e-02,  1.2980e-01,\n",
      "         -1.9424e-01,  1.9773e-01, -4.3516e-01],\n",
      "        [ 4.6528e-02,  1.5668e-03,  2.5372e-03, -6.7346e-01, -3.3359e-02,\n",
      "          1.2720e-02, -1.2200e-02, -4.1914e-02],\n",
      "        [-5.9338e-02,  2.4411e-03, -2.7623e-03, -1.1176e-02,  1.0936e-02,\n",
      "         -9.7964e-03,  4.2503e-02,  1.0177e+00],\n",
      "        [ 2.7732e-05, -6.4002e-05, -2.5877e-05,  1.0272e-05, -7.6049e-06,\n",
      "          3.9102e-05, -2.6984e-05, -2.0533e-05],\n",
      "        [ 4.9562e-02,  1.0627e-02,  2.5869e-03, -1.5897e+00, -8.3313e-02,\n",
      "          2.2313e-02, -4.3083e-03,  5.4991e-02]], requires_grad=True)\n",
      "b_1 Parameter containing:\n",
      "tensor([-2.9830e-01, -2.3101e-01,  1.6092e-01,  4.0474e-01, -1.5960e-01,\n",
      "         6.2052e-02,  1.4837e-03, -3.8434e-01, -3.3192e-01, -1.6254e-01,\n",
      "         4.1213e-01, -4.0923e-01,  1.7230e-02,  5.5169e-01, -2.7098e-01,\n",
      "        -1.9397e-01, -2.4090e-01, -2.0561e-01, -2.8640e-01,  2.4910e-01,\n",
      "         4.4970e-02,  2.0080e-01, -1.1952e-01,  1.9962e-01, -2.3408e-01,\n",
      "        -5.5205e-01, -3.6108e-01, -1.2196e-01,  2.6996e-01,  9.7083e-02,\n",
      "         8.5317e-01, -1.8584e-01, -7.3052e-06, -5.5606e-01,  1.9652e-06,\n",
      "         1.0020e-03,  3.8815e-01,  4.5674e-01, -8.6975e-01, -6.8611e-02,\n",
      "        -1.4665e-01, -1.4835e-01, -3.4344e-01,  6.8277e-02, -7.3664e-01,\n",
      "         6.5048e-01, -2.6737e-01,  1.7589e-01, -4.2642e-01,  4.0296e-01,\n",
      "         6.3933e-01, -3.1673e-01, -2.5484e-01, -5.8375e-02, -1.0743e-01,\n",
      "         2.1586e-01, -1.3436e-01, -4.6901e-01,  1.1224e-01, -1.9496e-01,\n",
      "         4.6646e-01, -8.1822e-01, -3.6351e-05,  2.3458e-01],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True)\n",
      "W_2 Parameter containing:\n",
      "tensor([[-1.6548e-01, -6.6943e-03, -4.8915e-03,  ..., -2.8771e-02,\n",
      "         -6.9771e-05, -1.5098e-01],\n",
      "        [-3.8894e-03, -1.0169e-04, -1.8631e-01,  ...,  2.3320e-02,\n",
      "          1.1817e-04, -5.7920e-03],\n",
      "        [-2.0205e-01,  1.6208e-02,  6.2865e-04,  ..., -4.2851e-02,\n",
      "         -1.5836e-04, -2.9667e-06],\n",
      "        ...,\n",
      "        [-2.6094e-05,  5.4215e-02,  3.3715e-05,  ..., -6.0024e-02,\n",
      "          8.5578e-05,  7.4026e-02],\n",
      "        [-2.0628e-01,  5.4677e-03,  4.8458e-03,  ..., -1.0183e-02,\n",
      "          1.4416e-04, -5.7903e-04],\n",
      "        [-1.5925e-01,  3.8437e-04, -5.5289e-04,  ..., -2.9123e-03,\n",
      "         -8.7245e-06, -2.7485e-02]], requires_grad=True)\n",
      "b_2 Parameter containing:\n",
      "tensor([ 2.2950e-02, -2.6891e-02,  4.0276e-02,  4.8653e-02,  4.3052e-02,\n",
      "        -2.9746e-01, -2.7227e-01,  4.2470e-02,  3.6495e-02,  3.5921e-02,\n",
      "         5.1349e-02, -9.1147e-02,  3.7366e-02,  5.4128e-02,  3.2487e-02,\n",
      "         1.1712e-02,  7.1657e-02,  5.3352e-02,  5.0999e-02,  4.1305e-02,\n",
      "         5.3762e-02,  4.0014e-02,  5.1557e-02,  3.4891e-02,  4.6329e-02,\n",
      "        -2.6054e-06,  3.8427e-02,  4.3749e-02, -7.3502e-02,  5.3622e-02,\n",
      "         2.8461e-02, -3.9258e-01,  2.8655e-02,  3.4366e-02, -1.1554e-01,\n",
      "         6.7380e-02,  6.4993e-02,  1.5199e-02,  4.0237e-02,  7.9818e-02,\n",
      "         2.7146e-02,  5.6265e-02,  2.7220e-02,  2.0307e-02,  4.4149e-02,\n",
      "        -3.5721e-01, -4.5842e-03, -4.3727e-02, -3.3942e-01, -3.3610e-01,\n",
      "         5.1826e-02, -7.5576e-02,  1.5953e-02,  6.0863e-02, -2.3765e-05,\n",
      "         5.4804e-02,  1.8235e-02,  3.6759e-02,  6.5866e-02,  4.3525e-02,\n",
      "         3.5013e-02, -7.7510e-02,  2.7580e-02,  2.4215e-02],\n",
      "       requires_grad=True)\n",
      "W_4 Parameter containing:\n",
      "tensor([[ 1.1174e+00, -1.2804e+00,  7.1869e-01,  1.5016e-03,  1.5423e-01,\n",
      "         -3.4153e-02,  6.0086e-01,  4.5325e-01,  9.6072e-01,  1.0047e+00,\n",
      "         -2.5054e-01, -9.8434e-01, -1.7475e-01, -2.7004e-01,  6.2269e-01,\n",
      "         -5.4778e-01,  1.7729e-01, -2.4910e-01,  8.9739e-04,  6.2594e-01,\n",
      "         -1.2208e-04,  4.1719e-01, -1.9787e-01, -7.1724e-01, -8.0016e-03,\n",
      "          4.2922e-07,  4.9071e-03,  1.2287e-03,  1.6404e+00, -5.3671e-01,\n",
      "          6.8886e-01, -1.6415e-02,  7.7774e-01,  6.6143e-01, -4.6174e-01,\n",
      "         -2.9532e-01, -2.3051e-01,  2.1284e-01, -3.6043e-01,  8.3158e-04,\n",
      "         -1.2151e+00, -7.2907e-03, -9.5414e-01,  2.7816e-01,  4.5871e-01,\n",
      "         -1.3690e-01,  8.2323e-01,  1.0333e+00,  4.8539e-04, -2.8621e-04,\n",
      "          5.6992e-04, -2.2515e-01,  3.3342e-02, -3.6171e-02,  4.7728e-05,\n",
      "         -3.8187e-01,  7.8315e-01,  1.1392e+00,  1.2305e-05,  3.9273e-01,\n",
      "          3.0737e-01,  1.5044e+00,  6.8008e-01,  3.3979e-01],\n",
      "        [-8.6497e-02,  1.5491e-04, -2.1583e-03,  1.1183e+00,  1.0600e+00,\n",
      "         -1.0954e+00, -1.0768e+00,  7.8895e-01, -2.2402e-03, -3.2689e-03,\n",
      "          7.4318e-01, -3.3273e-02,  5.0663e-01,  2.8413e-01, -7.5255e-03,\n",
      "          2.9968e-04, -1.0261e+00,  1.1233e+00,  7.5640e-01, -4.4834e-04,\n",
      "          8.5600e-01,  4.9844e-01,  8.0127e-01, -2.7428e-01,  1.1274e+00,\n",
      "          2.9058e-05,  6.2457e-01,  1.3109e+00, -4.7677e-03,  5.5979e-01,\n",
      "         -2.8742e-02, -7.4169e-01, -5.1534e-03, -7.3787e-02, -9.1456e-01,\n",
      "         -8.1353e-01,  1.2102e+00,  9.3138e-01, -1.3036e+00, -1.3388e+00,\n",
      "          1.4447e-01,  8.2264e-01, -1.6829e-01, -1.8200e-03,  9.2742e-01,\n",
      "         -6.5874e-01, -1.7550e-02, -1.4267e-01, -9.5550e-01, -6.9321e-01,\n",
      "          7.4830e-01, -1.4162e-01,  1.1841e+00,  1.1724e+00, -7.5009e-05,\n",
      "          3.6151e-01,  1.2875e-01, -3.5416e-01,  1.3502e+00,  7.5137e-01,\n",
      "         -1.8742e-04, -2.8613e-03, -2.2592e-02, -2.4821e-02]],\n",
      "       requires_grad=True)\n",
      "b_4 Parameter containing:\n",
      "tensor([0.3689, 0.3456], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Particle Swarm Optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start defining some functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_max(height, mesh_size, amplitude, phase_shift, omega, beta, k_max):\n",
    "    \"\"\" Function that calculate the new amplitude of the fiber path such that the\n",
    "        manifactuing constraint is not violated \"\"\"\n",
    "    x = np.linspace(mesh_size / 2, h - mesh_size / 2, 1000) \n",
    "    dy = omega * (2 * np.pi / h) * amplitude * np.cos(omega * (2 * np.pi / h) * x + phase_shift) + np.tan(beta )\n",
    "    ddy = - (omega**2) * (4 * (np.pi**2) / (h**2)) * amplitude * np.sin(omega * (2 * np.pi / h) * x + phase_shift)\n",
    "    k = ddy / ((1 + dy**2)**(1.5))\n",
    "\n",
    "    max_value = np.amax(abs(k))\n",
    "    max_pos = np.where(abs(k) == max_value)\n",
    "\n",
    "    if max_value > k_max:\n",
    "        def curvature(a_hat):\n",
    "            dy = omega * (2 * np.pi / h) * a_hat * np.cos(omega * (2 * np.pi / h) * x[max_pos[0][0]] + phase_shift) + np.tan(beta)\n",
    "            ddy = - (omega**2) * (4 * (np.pi**2) / (h**2)) * a_hat * np.sin(omega * (2 * np.pi / h) * x[max_pos[0][0]] + phase_shift)\n",
    "            return k_max - abs(ddy / ((1 + dy**2)**(1.5)))\n",
    "        new_a = fsolve(curvature, amplitude)\n",
    "    else:\n",
    "        new_a = amplitude\n",
    "    \n",
    "    return new_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the function to initialize the particles position and velocity. In this initialization, and in all the other steps, we have to check the manufacturing constraints of the generated candidate paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particles_init(particles, interval, min_boundaries, eff_plies):\n",
    "    \"\"\" Initialization function for the velocity and position of the swarm \"\"\"\n",
    "    position = None\n",
    "    velocity = None\n",
    "    deg2rad = np.pi / 180\n",
    "    for ply in range(1, eff_plies + 1):\n",
    "        design = pyDOE.lhs(interval.shape[1], particles)\n",
    "        x = design * interval + min_boundaries\n",
    "        for j in range(0, particles):\n",
    "            new_a = a_max(h, mesh_size, x[j, 0], x[j, 1] * deg2rad, x[j, 2], x[j, 3] * deg2rad, k_max)\n",
    "            x[j, 0] = new_a\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.copy(x)\n",
    "        else:\n",
    "            position = np.column_stack((position, x))\n",
    "            \n",
    "    for ply in range(1, eff_plies + 1):\n",
    "        design = pyDOE.lhs(interval.shape[1], particles)\n",
    "        x = design * interval + min_boundaries\n",
    "        for j in range(0, particles):\n",
    "            new_a = a_max(h, mesh_size, x[j, 0], x[j, 1] * deg2rad, x[j, 2], x[j, 3] * deg2rad, k_max)\n",
    "            x[j, 0] = new_a\n",
    "\n",
    "        if velocity is None:\n",
    "            velocity = np.copy(x) * 0.1\n",
    "        else:\n",
    "            velocity = np.column_stack((velocity, x)) * 0.4\n",
    "    return position, velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the function to **let the particles flyyyyy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fly(param, pos, vel, cognitive_pos_best, social_pos_best, boundaries, max_iter, run):\n",
    "    \"\"\" Function to let the swarm flies in the design space\"\"\"\n",
    "    deg2rad = np.pi / 180\n",
    "    w_max, w_min, c1, c2 = param\n",
    "    w = w_max - (w_max - w_min) / max_iter * run\n",
    "    \n",
    "    inertial_velocity = w * vel\n",
    "    cognitive_velocity = c1  * np.random.rand(particles, dimensions) * (cognitive_pos_best - pos)\n",
    "    social_velocity = c2 * np.random.rand(particles, dimensions) * (np.tile(social_pos_best, (particles, 1)) - pos)\n",
    "    \n",
    "    # Update velocities\n",
    "    new_vel = inertial_velocity + cognitive_velocity + social_velocity\n",
    "    \n",
    "    # Update positions\n",
    "    new_pos = pos + new_vel\n",
    "    \n",
    "    # Correct particles position\n",
    "    for ply in range(0, eff_plies):\n",
    "        # Generate a new temporary array for each ply\n",
    "        _new_pos = copy(new_pos[:, ply * interval.shape[1]: ply * interval.shape[1] + interval.shape[1]])\n",
    "        _new_vel = copy(new_vel[:, ply * interval.shape[1]: ply * interval.shape[1] + interval.shape[1]])\n",
    "        \n",
    "        # Generate an array of min and max values of the features\n",
    "        min_array = np.tile(boundaries[0, :], (particles, 1))\n",
    "        max_array = np.tile(boundaries[1, :], (particles, 1))\n",
    "        \n",
    "        # Correct out-of-boundaries features position\n",
    "        #print(\"Init : {:+04f} {:+04f} {:+04f} {:+04f}\".format(_new_vel[0, 0], _new_vel[0, 1], _new_vel[0, 2], _new_vel[0, 3]))\n",
    "\n",
    "        _new_vel[_new_pos < min_array] = -0.1 * _new_vel[_new_pos < min_array]\n",
    "        _new_vel[_new_pos > max_array] = -0.1 * _new_vel[_new_pos > max_array]\n",
    "        \n",
    "        #print(\"Init : {:+04f} {:+04f} {:+04f} {:+04f}\".format(_new_vel[0, 0], _new_vel[0, 1], _new_vel[0, 2], _new_vel[0, 3]))\n",
    "        _new_pos[_new_pos < min_array] = min_array[_new_pos < min_array]\n",
    "        _new_pos[_new_pos > max_array] = max_array[_new_pos > max_array]\n",
    "        \n",
    "        _new_pos[_new_pos < min_array] = _new_pos[_new_pos < min_array] + _new_vel[_new_pos < min_array]\n",
    "        _new_pos[_new_pos > max_array] = _new_pos[_new_pos > max_array] + _new_vel[_new_pos > max_array]\n",
    "        \n",
    "        # Correct manufacturing constraints\n",
    "        for j in range(0, particles):\n",
    "            new_a = a_max(h, mesh_size, _new_pos[j, 0], _new_pos[j, 1] * deg2rad,\n",
    "                          _new_pos[j, 2], _new_pos[j, 3] * deg2rad, k_max)\n",
    "            \n",
    "            if new_a != _new_pos[j, 0]:\n",
    "                #print('dentro')\n",
    "                #print(_new_pos[j, 0])\n",
    "                _new_pos[j, 0] = new_a\n",
    "                #print(_new_pos[j, 0])\n",
    "        \n",
    "        new_pos[:, ply * interval.shape[1]: ply * interval.shape[1] + interval.shape[1]] = _new_pos\n",
    "        new_vel[:, ply * interval.shape[1]: ply * interval.shape[1] + interval.shape[1]] = _new_vel\n",
    "                \n",
    "    return new_pos, new_vel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the function that, given the particles positions, evaluates the buckling load and the pre-bluckling stiffness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_prediction(model, position, x_bounds, y_bounds):\n",
    "    \"\"\" Function to predict the scores through a neural network\"\"\"\n",
    "    model.eval()\n",
    "    _X, _, _ = range_norm(position, x_min=x_bounds[0, :], x_max=x_bounds[1, :])\n",
    "    X = Variable(torch.from_numpy(_X.astype('float32')))\n",
    "    _Y = model(X)\n",
    "    Y = reverse_range_norm(_Y.detach().numpy(), y_bounds[0, :], y_bounds[1, :])\n",
    "    return Y[:, 0], Y[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define some parameters of the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1VxsJFUDoME"
   },
   "outputs": [],
   "source": [
    "particles = 80\n",
    "tot_opt = 2\n",
    "dimensions = interval.shape[1] * eff_plies\n",
    "max_iter = 1000\n",
    "w_max = 1.4\n",
    "w_min = 0.3\n",
    "c1 = 2\n",
    "c2 = 2\n",
    "param = [w_max, w_min, c1, c2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3SRjCCICBTY",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization: 01\n",
      "Optimization: 02\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "max_buckling = []\n",
    "opt_config = []\n",
    "    \n",
    "for opt in range(tot_opt):\n",
    "    \n",
    "    print(\"Optimization: {:02d}\".format(opt+1))\n",
    "    \n",
    "    # Initialize particles positions and velocities\n",
    "    pos, vel = particles_init(particles, interval, min_boundaries, eff_plies)\n",
    "    #print(\"Init : {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f}\".format(pos[0, 0], pos[0, 1], pos[0, 2], pos[0, 3], pos[0, 4], pos[0, 5], pos[0, 6], pos[0, 7]))\n",
    "\n",
    "    # Predict the score associated with each particle\n",
    "    bck, stiff = net_prediction(model, pos, x_bounds, y_bounds)\n",
    "\n",
    "    # The score is the inverse of the buckling load\n",
    "    score = 1 / bck\n",
    "\n",
    "    # Set to zero score value less than zero. We look for the highest positive buckling value.\n",
    "    score[score < 0] = np.inf\n",
    "\n",
    "    # initialization of particles and swarm scores\n",
    "    cognitive_best = copy(score)\n",
    "    cognitive_pos_best = copy(pos)\n",
    "    social_best = score[np.argmin(score)]\n",
    "    social_pos_best = pos[np.argmin(score), :]\n",
    "    buckling_hist = []  # contains envelope of best buckling\n",
    "\n",
    "    for run in range(max_iter):\n",
    "        # Fly\n",
    "        #print(\"Pre fly : {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f}\".format(pos[0, 0], pos[0, 1], pos[0, 2], pos[0, 3], pos[0, 4], pos[0, 5], pos[0, 6], pos[0, 7]))\n",
    "        pos, vel = fly(param, pos, vel, cognitive_pos_best, social_pos_best, boundaries, max_iter, run)\n",
    "        #print(\"Post fly: {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f} {:+04f}\".format(pos[0, 0], pos[0, 1], pos[0, 2], pos[0, 3], pos[0, 4], pos[0, 5], pos[0, 6], pos[0, 7]))\n",
    "\n",
    "        # Evaluate score\n",
    "        bck, stiff = net_prediction(model, pos, x_bounds, y_bounds)\n",
    "        score = 1 / bck\n",
    "        score[score < 0] = np.inf\n",
    "\n",
    "        cognitive_best[cognitive_best > score] =  score[cognitive_best > score]\n",
    "        cognitive_pos_best[cognitive_best > score, :] =  pos[cognitive_best > score, :]\n",
    "\n",
    "        if score[np.argmin(score)] < social_best:\n",
    "            social_best = score[np.argmin(score)]\n",
    "            social_pos_best = pos[np.argmin(score), :]\n",
    "            #print(\"Iteration: {:04d}, actual maximum torsional buckling: {}\".format(run, bck[np.argmin(score)]))\n",
    "            \n",
    "    max_buckling.append(1 / social_best)\n",
    "    opt_config.append(social_pos_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buckling</th>\n",
       "      <th>Amplitude1</th>\n",
       "      <th>PhaseShift1</th>\n",
       "      <th>Omega1</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Amplitude2</th>\n",
       "      <th>PhaseShift2</th>\n",
       "      <th>Omega2</th>\n",
       "      <th>Beta2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>46610.092183</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.300813</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5.081572</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.015208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>47255.633413</td>\n",
       "      <td>-114.293289</td>\n",
       "      <td>-21.889275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-90.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Buckling  Amplitude1  PhaseShift1    Omega1  Beta1  Amplitude2  \\\n",
       "0  46610.092183  200.000000    90.000000  0.300813   90.0    5.081572   \n",
       "1  47255.633413 -114.293289   -21.889275  0.000000   90.0  200.000000   \n",
       "\n",
       "   PhaseShift2  Omega2      Beta2  \n",
       "0        -90.0     2.0   7.015208  \n",
       "1         90.0     2.0 -90.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_config = np.array(opt_config)\n",
    "max_buckling = np.array(max_buckling)\n",
    "max_buckling = max_buckling.reshape((-1, 1))\n",
    "results = np.hstack((max_buckling, opt_config))\n",
    "columns = ['Buckling',\n",
    "           'Amplitude1', 'PhaseShift1', 'Omega1', 'Beta1',\n",
    "           'Amplitude2', 'PhaseShift2', 'Omega2', 'Beta2']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './' + load_case + '/' + stacking_sequence + '/' + data_set + '/' + fiber_path + '/'\n",
    "try:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "except OSError:\n",
    "    print('Error: Creating directory. ' + output_folder)\n",
    "results_df.to_csv(output_folder + 'results.csv', index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2KpjBYmG7+zswyvIZyQz3",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "PSO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
